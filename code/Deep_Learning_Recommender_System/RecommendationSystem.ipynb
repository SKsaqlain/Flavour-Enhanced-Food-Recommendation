{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecommendationSystem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQOe75Tt57f6",
        "colab_type": "text"
      },
      "source": [
        "Recommendation System implemented Using DeepCoNN architecture with input being user food reviews, food flavanoids data and using tf-idf for embedding.    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro69eqw47Klz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "4bdf7f67-6807-4be6-9b46-7b8c6eae8839"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "from keras.layers import Input, Dense , Embedding\n",
        "from keras.layers.merge import Add, Dot, Concatenate\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJtwmaD7Nnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "db765308-26b0-4ffc-8cc6-a87750211f97"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVLsu3Np7i__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp2OkZ4b7z5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "acde7292-f2aa-49ae-fa5a-3c0259f85cfa"
      },
      "source": [
        "rawData=pd.read_csv('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/unembedded_grouped_cleaned_data.csv')\n",
        "rawData.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9974</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10340</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['feeling', 'healthy', 'great', 'replication',...</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12047</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['yum', 'will', 'make', 'again']</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13451</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['turned', 'out', 'great', 'i', 'added', 'pean...</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>18226</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['fantastic', 'tasting', 'completely', 'simple...</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                 foodReviews\n",
              "0           0  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
              "1           1  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
              "2           2  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
              "3           3  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
              "4           8  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oip07vDu707D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "bced918d-3d24-49c0-98da-77846e50006c"
      },
      "source": [
        "rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "rawFlavanoids.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>flavanoids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id                                         flavanoids\n",
              "0           0   1  Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...\n",
              "1           1   2  AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...\n",
              "2           2   3  3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...\n",
              "3           3   4  AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...\n",
              "4           4   5  3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfsNrhhm8SzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8dd6d798-7cc4-43d5-9a35-9a1f20ce2d48"
      },
      "source": [
        "flavanoidDB={}\n",
        "for i in range(rawFlavanoids.shape[0]):\n",
        "  flavanoidDB[str(rawFlavanoids[\"id\"][i])]=str(rawFlavanoids[\"flavanoids\"][i].split(\"|\"))\n",
        "print(\"total flanavnoids={}\".format(len(flavanoidDB)))\n",
        "print(list(flavanoidDB.keys())[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total flanavnoids=1380\n",
            "['1', '2', '3', '4', '5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2P8aGBy-P_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processedData=rawData.copy()\n",
        "for ele in flavanoidDB.keys():\n",
        "  try:\n",
        "    processedData.loc[processedData[\"food_id\"]==ele,\"foodReviews\"]=flavanoidDB[ele]\n",
        "  except:\n",
        "    print(\"food id {} not found in the dataset\".format(ele))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXb5pfK7GWx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c7e4ea48-d57a-4803-8acc-e80ab8a69202"
      },
      "source": [
        "processedData.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9974</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10340</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['feeling', 'healthy', 'great', 'replication',...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12047</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['yum', 'will', 'make', 'again']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13451</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['turned', 'out', 'great', 'i', 'added', 'pean...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>18226</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['fantastic', 'tasting', 'completely', 'simple...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        foodReviews\n",
              "0           0  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "1           1  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "2           2  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "3           3  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "4           8  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DRP1H-SIPAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train/test split for our model is unique, we need to hold out a\n",
        "# set of users and movies so that our network never learns those \n",
        "testSize = 0.005\n",
        "\n",
        "# get testSize percentage of users\n",
        "uniqueUsers = processedData.loc[:, \"user_id\"].unique()\n",
        "usersSize = len(uniqueUsers)\n",
        "test_idx = np.random.choice(usersSize,\n",
        "                              size=int(usersSize * testSize),\n",
        "                              replace=False)\n",
        "\n",
        "# get test users\n",
        "testUsers = uniqueUsers[test_idx]\n",
        "\n",
        "# everyone else is a training user\n",
        "trainUsers = np.delete(uniqueUsers, test_idx)\n",
        "\n",
        "test = processedData[processedData[\"user_id\"].isin(testUsers)]\n",
        "train = processedData[processedData[\"user_id\"].isin(trainUsers)]\n",
        "\n",
        "uniqueTestFood = test[\"food_id\"].unique()\n",
        "\n",
        "# drop the movies that also appear in our test set. In order to be\n",
        "# a true train/test split, we are forced to discard some data entirely\n",
        "train = train.where(np.logical_not(train[\"food_id\"].isin(uniqueTestFood))).dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ANBx5tnIvtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ce7dd9b-414a-458a-d435-b463d02bcddb"
      },
      "source": [
        "print(\"train={} test={}\".format(train.shape,test.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train=(16603, 6) test=(280, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3BRQ0uTI4rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def cleanDoc(doc):\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in doc]\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\tstop_words = set(stopwords.words('english'))\n",
        "\ttokens = [w for w in tokens if not w in stop_words]\n",
        "\ttokens = [word for word in tokens if len(word) > 1]\n",
        "\treturn tokens\n",
        "\n",
        "def cnvStrToList(data):\n",
        "  for i in  range(len(data)):\n",
        "    if(data[i][-1]==\"]\"):\n",
        "      data[i]=eval(data[i])\n",
        "    else:\n",
        "      data[i]=eval(data[i]+\"]\")\n",
        "  return data\n",
        "\n",
        "\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None) \n",
        "# tfidf=TfidfVectorizer(max_features=241)\n",
        "\n",
        "\n",
        "#trainUserReviewsRaw=train[\"userReviews\"].tolist()\n",
        "\n",
        "trainUserReviewsProcessed=[cleanDoc(ele) for ele in cnvStrToList(train[\"userReviews\"].tolist())]\n",
        "testUserReviewsProcessed=[cleanDoc(ele) for ele in cnvStrToList(test[\"userReviews\"].tolist())]\n",
        "tfidf.fit(trainUserReviewsProcessed)\n",
        "\n",
        "\n",
        "tfidf_features=tfidf.transform(trainUserReviewsProcessed)\n",
        "\n",
        "trainUserReviews=tfidf_features.toarray()\n",
        "\n",
        "testUserReviews=tfidf.transform(testUserReviewsProcessed).toarray()\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None) \n",
        "\n",
        "trainFoodReviewsProcessed=cnvStrToList(train[\"foodReviews\"].tolist())\n",
        "testFoodReviewesProcessed=cnvStrToList(test[\"foodReviews\"].tolist())\n",
        "tfidf.fit(trainFoodReviewsProcessed)\n",
        "trainFoodReviews=tfidf.transform(trainFoodReviewsProcessed).toarray()\n",
        "testFoodReviews=tfidf.transform(testFoodReviewesProcessed).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKt0GMiJLaAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb00a7dc-7dd0-4d38-f191-1d1eea9cf019"
      },
      "source": [
        "print(\"Embedding Dimensions => userReviews={} || foodReviews={}\".format(trainUserReviews.shape,trainFoodReviews.shape))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding Dimensions => userReviews=(16603, 6484) || foodReviews=(16603, 1401)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3TjSeG5MAzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepCoNN():\n",
        "    def __init__(self,\n",
        "                 userEmbeddingSize,\n",
        "                 foodEmbeddingSize,\n",
        "                 hiddenSize,\n",
        "                 filters=2,\n",
        "                 kernelSize=10,\n",
        "                 strides=6):\n",
        "        self.userEmbeddingSize = userEmbeddingSize\n",
        "        self.foodEmbeddingSize=foodEmbeddingSize\n",
        "        self.hiddenSize = hiddenSize\n",
        "        self.filters = filters\n",
        "        self.kernelSize = kernelSize\n",
        "        self.inputU, self.towerU = self.createDeepCoNnTower(self.userEmbeddingSize)\n",
        "        self.inputF, self.towerF = self.createDeepCoNnTower(self.foodEmbeddingSize)\n",
        "        self.joined = Concatenate()([self.towerU, self.towerF])\n",
        "        self.outNeuron = Dense(1)(self.joined)\n",
        "\n",
        "    def createDeepCoNnTower(self,embeddingSize):\n",
        "        inputLayer = Input(shape=(embeddingSize,))\n",
        "        embeddingLayer=Embedding(embeddingSize,100)(inputLayer)\n",
        "        tower = Conv1D(filters=self.filters,\n",
        "                       kernel_size=self.kernelSize,\n",
        "                       activation=\"tanh\")(embeddingLayer)\n",
        "        tower = MaxPooling1D()(tower)\n",
        "        tower = Flatten()(tower)\n",
        "        tower = Dense(self.hiddenSize, activation=\"relu\")(tower)\n",
        "        return inputLayer, tower\n",
        "\n",
        "    def createDeepCoNnDp(self):\n",
        "        dotproduct = Dot(axes=1)([self.towerU, self.towerF])\n",
        "        output = Add()([self.outNeuron, dotproduct])\n",
        "        self.model = Model(inputs=[self.inputU, self.inputF], outputs=[output])\n",
        "        self.model.compile(optimizer='Adam', loss='mse')\n",
        "        \n",
        "    def train(self, trainData,trainUserReviews,trainFoodReviews, batch_size, epochs=1):\n",
        "        tensorboard = TensorBoard(log_dir=\"tf_logs/{}\".format(pd.Timestamp(int(time()), unit=\"s\")))\n",
        "        self.createDeepCoNnDp()\n",
        "        print(self.model.summary())\n",
        "        \n",
        "        # userReviews = np.array(trainData.loc[:, \"userReviews\"])\n",
        "        # foodReviews = np.array(trainData.loc[:, \"foodReviews\"])\n",
        "        userReviews=trainUserReviews\n",
        "        foodReviews=trainFoodReviews\n",
        "\n",
        "        self.train_inputs = [userReviews, foodReviews]\n",
        "        self.train_outputs = trainData.loc[:, \"rating\"]\n",
        "        \n",
        "        self.history = self.model.fit(self.train_inputs,\n",
        "                                      self.train_outputs,\n",
        "                                      callbacks=[tensorboard],\n",
        "                                      validation_split=0.05,\n",
        "                                      batch_size=batch_size,\n",
        "                                      epochs=epochs)\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCEiaBGRqN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "670f8dd8-81e5-4d64-90c4-a40ba685d2c3"
      },
      "source": [
        "hiddenSize = 64\n",
        "\n",
        "deepconn = DeepCoNN(trainUserReviews.shape[1],trainFoodReviews.shape[1], hiddenSize)\n",
        "\n",
        "batch_size = 32\n",
        "deepconn.train(train,trainUserReviews,trainFoodReviews, batch_size, epochs=10)\n",
        "\n",
        "deepconn.model.save(\"cnn.h5\")\n",
        "# print(train_embedded.loc[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 7365)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1401)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 7365, 100)    736500      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1401, 100)    140100      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 7356, 2)      2002        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 1392, 2)      2002        embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 3678, 2)      0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 696, 2)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 7356)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1392)         0           max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           470848      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           89152       flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 1)            0           dense_3[0][0]                    \n",
            "                                                                 dot_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,440,733\n",
            "Trainable params: 1,440,733\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 15772 samples, validate on 831 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            "15772/15772 [==============================] - 732s 46ms/step - loss: 0.9940 - val_loss: 0.6334\n",
            "Epoch 2/10\n",
            "15772/15772 [==============================] - 737s 47ms/step - loss: 0.6854 - val_loss: 0.6952\n",
            "Epoch 3/10\n",
            "15772/15772 [==============================] - 741s 47ms/step - loss: 0.7285 - val_loss: 0.6653\n",
            "Epoch 4/10\n",
            "15772/15772 [==============================] - 741s 47ms/step - loss: 0.6903 - val_loss: 0.6962\n",
            "Epoch 5/10\n",
            "15772/15772 [==============================] - 740s 47ms/step - loss: 0.6975 - val_loss: 0.6443\n",
            "Epoch 6/10\n",
            "15772/15772 [==============================] - 739s 47ms/step - loss: 0.6935 - val_loss: 0.6296\n",
            "Epoch 7/10\n",
            "15772/15772 [==============================] - 743s 47ms/step - loss: 0.6804 - val_loss: 0.6330\n",
            "Epoch 8/10\n",
            "15772/15772 [==============================] - 738s 47ms/step - loss: 0.6926 - val_loss: 0.6454\n",
            "Epoch 9/10\n",
            "15772/15772 [==============================] - 743s 47ms/step - loss: 0.6823 - val_loss: 0.6292\n",
            "Epoch 10/10\n",
            "15772/15772 [==============================] - 741s 47ms/step - loss: 0.6905 - val_loss: 0.6418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rotX_tNNSKra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "c37ea5ff-b246-4498-cb9b-7bf11bacb854"
      },
      "source": [
        "\n",
        "testInputs = [testUserReviews, testFoodReviews]\n",
        "print(testInputs)\n",
        "# dat = pd.DataFrame(testInputs)\n",
        "# dat.to_csv(\"/content/gdrive/My Drive/DeepConn/Deep_Learning_Recommender_System//test_data.csv\")\n",
        "\n",
        "trueRating = np.array(list(test.loc[:, \"rating\"])).reshape((-1, 1))\n",
        "\n",
        "predictions = deepconn.model.predict(testInputs)\n",
        "\n",
        "error = np.square(predictions - trueRating)\n",
        "\n",
        "print(\"MSE:\", np.average(error))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0.        , 0.        , 0.        , ..., 0.03534909, 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.0265084 , 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.03090472, 0.        ,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [0.        , 0.        , 0.        , ..., 0.02239758, 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.02239758, 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.06635533, 0.        ,\n",
            "        0.        ]])]\n",
            "MSE: 0.7254036919904203\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}