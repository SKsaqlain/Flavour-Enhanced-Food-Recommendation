{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQOe75Tt57f6",
        "colab_type": "text"
      },
      "source": [
        "Recommendation System implemented Using DeepCoNN architecture with input being user food reviews, food flavanoids data and using tf-idf for embedding.    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro69eqw47Klz",
        "colab_type": "code",
        "outputId": "927579fc-894c-463c-e510-f578c147d4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip install geocoder\n",
        "!pip install pyowm\n",
        "!pip install prettytable\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import linalg\n",
        "from time import time\n",
        "import os\n",
        "import pickle\n",
        "from prettytable import PrettyTable\n",
        "from random import randrange as get\n",
        "\n",
        "import geocoder\n",
        "import json\n",
        "import requests\n",
        "import pyowm\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import string \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model,model_from_json\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "from keras.layers import Input, Dense , Embedding\n",
        "from keras.layers.merge import Add, Dot, Concatenate\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 91kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting geocoder\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/6b/13166c909ad2f2d76b929a4227c952630ebaf0d729f6317eb09cbceccbab/geocoder-1.38.1-py2.py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from geocoder) (2.21.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from geocoder) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from geocoder) (7.1.1)\n",
            "Collecting ratelim\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/98/7e6d147fd16a10a5f821db6e25f192265d6ecca3d82957a4fdd592cad49c/ratelim-0.1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from geocoder) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2020.4.5.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ratelim->geocoder) (4.4.2)\n",
            "Installing collected packages: ratelim, geocoder\n",
            "Successfully installed geocoder-1.38.1 ratelim-0.1.6\n",
            "Collecting pyowm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/2a/83e26bc87763d0d34767ddc5c875608d4a0a0da66e59730a15c55aec6eff/pyowm-2.10.0-py3-none-any.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from pyowm) (2.21.0)\n",
            "Collecting geojson<3,>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (2020.4.5.1)\n",
            "Installing collected packages: geojson, pyowm\n",
            "Successfully installed geojson-2.5.0 pyowm-2.10.0\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJtwmaD7Nnm",
        "colab_type": "code",
        "outputId": "de4c4813-a19b-4fb6-e473-c2c1c08ed418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp2OkZ4b7z5G",
        "colab_type": "code",
        "outputId": "561a61fe-2514-45df-9e8a-7b1cb73d1b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "rawData=pd.read_csv('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/unembedded_grouped_cleaned_data.csv')\n",
        "# print(\"before sampleing \",rawData.shape)\n",
        "# print(rawData.head())\n",
        "# data5=rawData[rawData[\"rating\"]==5]\n",
        "# data4=rawData[rawData[\"rating\"]==4]\n",
        "# data3=rawData[rawData[\"rating\"]==3]\n",
        "# data2=rawData[rawData[\"rating\"]==2]\n",
        "# data1=rawData[rawData[\"rating\"]==1]\n",
        "# #after sampling\n",
        "# rawData=pd.concat([data1,data2,data3.sample(1380),data4.sample(1380),data5.sample(1380)])\n",
        "# print(\"after sampling \",rawData.shape)\n",
        "print(rawData.head())\n",
        "print(rawData.shape)\n",
        "#rawData=rawData[list(map(lambda x:len(x)>1,rawData[\"userReviews\"]))]\n",
        "print(rawData.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  ...                                 foodReviews\n",
            "0           0  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "1           1  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "2           2  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "3           3  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "4           8  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "(58283, 6)\n",
            "(58283, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oip07vDu707D",
        "colab_type": "code",
        "outputId": "13df3e43-4ce5-4b6a-f919-5a158bff47dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "# rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/database.csv\",names=[\"id\",\"flavanoids\"])\n",
        "# print(rawFlavanoids.shape)\n",
        "rawFlavanoids.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>flavanoids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id                                         flavanoids\n",
              "0           0   1  Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...\n",
              "1           1   2  AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...\n",
              "2           2   3  3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...\n",
              "3           3   4  AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...\n",
              "4           4   5  3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfsNrhhm8SzO",
        "colab_type": "code",
        "outputId": "81d38bae-01a4-4b93-d510-d85d98b9eccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "flavanoidDB={}\n",
        "for i in range(rawFlavanoids.shape[0]):\n",
        "  flavanoidDB[str(rawFlavanoids[\"id\"][i])]=str([ele.strip().replace(\" \",\"-\") for ele in rawFlavanoids[\"flavanoids\"][i].split(\"|\")])\n",
        "print(\"total dishes={}\".format(len(flavanoidDB)))\n",
        "print(list(flavanoidDB.keys())[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total dishes=1380\n",
            "['1', '2', '3', '4', '5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLUkY_TMdsRh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c3d7cdc3-ac31-4659-b582-0351222459ce"
      },
      "source": [
        "print(flavanoidDB[\"1\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ethyl-Lactate', '3,4-Dihydroxybenzaldehyde', 'DL-Liquiritigenin', '2-Acetylpyrrole', 'benzaldehyde', 'Ethyl-Vinyl-Ketone', '5-Hydroxymethylfurfural', '2,3,5-Trimethylpyrazine', 'Octan-2-ol', '2-Butanone', 'coumarin', 'indole', 'CHEBI:49249', 'Isobutyl-isothiocyanate', '2-Isobutyl-3-Methoxypyrazine', 'Allyl-methyl-sulfide', 'Humulene', 'AC1L9CNW', 'Vitamin-U', 'Alpha-Terpinyl-Acetate', 'S-Propyl-thioacetate', 'Terpinen-4-ol', 'Isobornyl-acetate', 'Phlorizin', 'Methyl-tetradecanoate', '(Z)-Hex-3-en-1-ol', '.alpha.-Calacorene', 'Tetrasulfide,-dimethyl', 'M-Cymene', '(-)-Epicatechin-gallate', 'Methyleugenol', '2-Nonanol', 'cinnamaldehyde', '2-Hexanone', 'Valencene', '2-Methylbutyraldehyde', '3,5-Diethyl-1,2,4-trithiolane', 'Isobutyl-Acetate', 'Coumestrol', 'Ocimene', 'farnesol', 'Citral', '2-isopropyl-6-methoxypyrazine', 'hydrogen-cyanide', 'Ethyl-Propyl-Disulfide', 'Methyl-propyl-disulfide', '2-Mercapto-2-Methyl-1-Pentanol', 'Hexanal', 'Damascenone', '2,3-butanedione', '1,3-Dithiane', '3,4-Dimethylphenol', 'Heptanal', 'Propyl-sulfide', 'trans,trans-2,4-Nonadienal', 'trans-2-Nonenal', 'Ethyl-Acetate', 'gamma-Caprolactone', 'D-Lactic-acid', 'Tetradecanoic-acid', '3-Octanone', 'Isobutyl-Formate', 'hydrogen-sulfide', 'Isovaleric-Acid', 'cis-Jasmone', 'D-mannitol', '156420-69-8', 'Cianidanol', 'Methyl-Benzoate', 'Eucalyptol', 'Pentanal', 'Propenyl-propyl-disulfide', 'Methyl-Stearate', 'Allyl-Mercaptan', 'Curcumenol', 'Linalool', 'alpha-Cadinene', 'Menthone', 'palmitic-acid', 'Diallyl-trisulfide', 'Pyridine', '1-Dodecanol', 'Ethyl-Benzoate', 'Hexyl-acetate', 'Nerolidyl-acetate', 'indole-3-acetic-acid', '2-Acetyl-2-thiazoline', '2,6-Dimethylpyrazine', '3-Methylcyclopentane-1,2-dione', 'Nonanal', 'Tributyrin', 'Pyruvic-acid', 'Terpinolene', 'UNII-M41Y60O5BZ', '4-Methyl-5-Thiazoleethanol', 'Isoquercitrin', '2-Phenylethanol', 'Linalyl-Acetate', 'Diisopropyl-trisulfide', 'Gamma-Terpinene', 'Diallyl-Disulfide', '3-Phenylpropanoic-acid', 'Beta-Phellandrene', 'phloretin', 'Carvacrol', 'Curcumene', 'dimethyl-sulfide', 'Ethyl-Formate', '2,6-Dimethoxyphenol', 'carnosol', 'Disulfide,-methyl-1-propenyl', '1-octanol', '2-Isopropyl-5-methylcyclohexanone', 'Beta-Caryophyllene', 'Neral', '1-Propanethiol', 'Phytol', '1-Octen-3-Ol', 'daidzein', 'Methyl-octanoate', 'nan', 'cis-Isoeugenol', 'Alpha-Ionone', 'Dipropyl-trisulfide', 'Daidzin', 'Beta-Pinene', 'Allyl-Methyl-Disulfide', 'Isopentyl-formate', '2-Acetyl-5-Methylfuran', '2-Methyl-2-Pentenal', '(Z)-cinnamyl-alcohol', '2-Heptanone', 'sulfur-dioxide', 'Dipentene', 'Methyl-Acetate', '2-Methyl-1-propanol', 'methanethiol', 'Sinapic-Acid', 'Isoamyl-Acetate', 'quercetin', 'L-Rhamnose', 'isopropanol', '2-Pentanol', '2-Methyl-1-Butanol', '3-Carene', '2-Isopropyl-3-Methoxypyrazine', 'Vanillic-acid', 'Furfuryl-acetate', '2,3-Pentanedione', '.alpha.-Cubebene', '2-Heptanol', '(-)-Zingiberene', 'butein', '24168-70-5', '2-Nonanone', 'calcium-lactate', '3-Hexanone', '(-)-gamma-cadinene', 'hydrogen-peroxide', '(5xi,7xi,10xi)-eudesma-4(14),11-diene', 'S-allyl-L-cysteine', 'Methyl-propyl-trisulfide', 'gamma-Decalactone', '(-)-Epigallocatechin', 'gamma-Butyrolactone', 'methyl-(9E,12Z)-octadeca-9,12-dienoate', '4-Methyl-5-Vinylthiazole', '3-methylthiopropanol', '2-(4-Hydroxyphenyl)ethanol', 'Tangeretin', 'gamma-Nonanolactone', 'Cyclopentanone', 'Carvone', '(Z)-Ethyl-cinnamate', 'methyl-salicylate', '6-Methyl-5-Hepten-2-One', 'Tiglic-aldehyde', '2,3-Dimethylbenzofuran', 'D-Isoleucine-Methyl-Ester-Hydrochloride', 'D-Camphor', 'betaine', 'P-Cymene', '4-Methyl-2-pentanone', '(+)-alpha-Terpineol', '2-Methyltetrahydrofuran-3-One', '3-Pentanone', 'Cinnamic-Acid', '4-isopropylbenzaldehyde', 'Styrene', 'phenol', '2-Ethyl-4-hydroxy-5-methyl-3(2H)-furanone', 'Methyl-jasmonate', '(Z)-Hex-4-enal', 'resveratrol', '(+)-Camphene', 'Cubenol', '3-Ethyl-2,5-dimethylpyrazine', '1-Popc', 'acetic-acid', '2-Phenylethyl-formate', 'trans-Anethole', '2-Undecanol', 'succinic-acid', 'alpha-Cadinol', 'Dl-Methionine', 'salicylic-acid', 'Isobutyraldehyde', '3-Thujene', 'CID-644104', '1,3-Diphenyl-1-butanone', 'Gallocatechin', 'dibutyl-phthalate', 'Geraniol', 'Acrolein', '5-Methylfurfural', 'D-Limonene', 'Isopentyl-benzoate', 'Thiamine-Hydrochloride', '2,5-Dimethylthiophene', '(+)-Neomenthol', 'l-.alpha.-Cadinol', '2-Methylbutyl-Acetate', 'Isoborneol', '1-(4-Methylphenyl)ethanol', '3-Mercapto-2-methylpentanal', '3-Methyl-2-Cyclopenten-1-One', 'Benzyl-Salicylate', '(+)-delta-Cadinene', 'Octanal', 'Acetal', '3-Methylbutanal', 'Ethyl-Cinnamate', 'Beta-Ionone', 'Acetyleugenol', 'cis-Cinnamic-acid', '3-Methyl-2-butenal', '3-Methoxybenzaldehyde', 'octanoic-acid', 'benzyl-isothiocyanate', 'Ethyl-Octanoate', '2-Pentyl-Acetate', '33368-82-0', 'Isopropyl-Acetate', 'eugenol', 'guaiacol', '2-amino-3-(prop-2-en-1-ylsulfanyl)propanoic-acid', 'UNII-H5E892YJGG', 'Phenylacetic-Acid', '2-Pentanone', 'Undecanoic-Acid', 'Pyrrolidine', 'Allyl-propyl-sulfide', 'benzoic-acid', 'DL-Tartaric-acid', 'Benzyl-tiglate', 'Linamarin', '3,4-Dihydroxybenzoic-Acid', '2-Methoxy-4-vinylphenol', '3242-08-8', 'Acetophenone', '4-Hexen-1-Ol', '2-Methylbenzaldehyde', 'Nerolidol', '2-Furylacetone', 'Farnesal', 'Butyl-propyl-disulfide', '2-Acetylthiazole', 'Maltol', 'naringenin', '1-Pyrroline', '2,5-Dimethylpyrazine', 'Alpha-Terpinene', 'Dimethyl-disulfide', 'propionic-acid', '.beta.-Bourbonene', 'trans-2-Hexen-1-Ol', 'Dipropyl-disulfide', '2,6-Di-tert-butyl-4-methylphenol', 'NSC5112', '1-Methylnaphthalene', 'Hexanoic-Acid', 'Alpha-Pinene', 'Phenethyl-acetate', '2-Methylpyrazine', 'Aromadendrene', '6753-98-6', '(E)-gamma-Bisabolene', 'Ethyl-Levulinate', 'trans-3-Hexen-1-ol', 'Borneol', 'Beta-Selinene', '1-Nonanol', 'Beta-Elemene', 'Taxifolin', 'Myrcene', '1-Hexanol', 'Caryophyllene', 'Juniper-camphor', 'Allyldimethylsilane', '4-Vinylphenol', 'Octan-2-one', '1-Phenylethyl-acetate', 'Furfuryl-Alcohol', 'Ethyl-caproate', 'lauric-acid', 'kaempferol', 'Camphene', '4-Hexen-3-One', 'Thymol', 'Isoeugenol', 'isoliquiritigenin', '2,3,5,6-Tetramethylpyrazine', 'Allyl-Alcohol', '3-Hexanol', 'ethanol', 'alpha-Muurolene', '227456-27-1', '2-Methylpentanal', 'caftaric-acid', '3-Methyl-2-Butanol', '(-)-Epicatechin', 'Allyl-Isothiocyanate', 'Thymol-methyl-ether', 'cis-3-Hexenal', 'acetone', '(-)-Limonene', '3-Methyl-2-Buten-1-Ol', 'Beta-Terpineol', 'p-coumaric-acid', 'Clove-Oil', '4-hydroxybenzaldehyde', 'S-Methyl-thioacetate', 'alpha-TERPINEOL', 'D-Fenchone', 'Estragole', '3-Heptanone', '7-methyl-4-methylidene-1-propan-2-yl-2,3,4a,5,6,8a-hexahydro-1H-naphthalene', '2-Furaldehyde', 'gingerol', 'Dl-Phenylalanine', 'Methyl-propenyl-ketone', '(-)-Epigallocatechin-gallate', 'Acetovanillone', '(E)-Hept-2-enal', 'apigenin', 'vanillin', '3-Methyl-2-Cyclohexen-1-One', 'Diallyl-Sulfide', 'Dimethyl-trisulfide', 'Alpha-Phellandrene', 'luteolin', '1-propanol', 'phenylacetaldehyde', '(+)-alpha-phellandrene', 'Propyl-butyrate', 'Benzyl-Acetate', '3-Methyl-1-butanol', '1-Phenylethanol', 'Benzyl-Benzoate', 'Isobutyl-butyrate', '2-Acetylpyridine', '4-isopropylbenzyl-alcohol', 'Isorhamnetin', '1-Penten-3-Ol', '2-Pentylfuran', 'L-histidine', 'Propyl-acetate', 'Chavicol', 'AC1NST8Q', 'Syringaldehyde', 'Nonanoic-Acid', '2-Undecanone', 'nicotine', '.beta.-Sesquiphellandrene', 'Sabinene-hydrate', 'Methyl-Palmitate', 'Neryl-propionate', 'cinnamyl-alcohol', 'Piperitol', 'cis-3-Hexenyl-acetate', 'Geranyl-Acetate', 'Allyl-Propyl-Disulfide', '(+)-gamma-cadinene', 'naphthalene', '2-Methylbutanoic-acid', 'benzyl-alcohol', 'alpha-Maltose', 'alpha-L-Sorbopyranose', 'Ethyl-Butyrate', 'Heptanoic-Acid', 'thiamine', 'Allyl-Methyl-Trisulfide', '2-Tridecanone', 'L-phenylalanine', 'Propionaldehyde', '3-(Methylthio)propionaldehyde', 'Caryophyllene-oxide', 'Diallyl-tetrasulfide', 'dimethyl-sulfoxide', 'Propyl-Benzoate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2P8aGBy-P_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processedData=rawData.copy()\n",
        "for ele in flavanoidDB.keys():\n",
        "  try:\n",
        "    processedData.loc[processedData[\"food_id\"]==ele,\"foodReviews\"]=flavanoidDB[ele]\n",
        "  except:\n",
        "    print(\"food id {} not found in the dataset\".format(ele))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXb5pfK7GWx6",
        "colab_type": "code",
        "outputId": "368448fe-3952-4130-b765-3c80dd9b5431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "processedData.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9974</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10340</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['feeling', 'healthy', 'great', 'replication',...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12047</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['yum', 'will', 'make', 'again']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13451</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['turned', 'out', 'great', 'i', 'added', 'pean...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>18226</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['fantastic', 'tasting', 'completely', 'simple...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        foodReviews\n",
              "0           0  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "1           1  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "2           2  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "3           3  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "4           8  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0LKJy5oN_Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "userReviews=processedData[\"userReviews\"].tolist()\n",
        "foodReviews=processedData[\"foodReviews\"].tolist()\n",
        "def cleanDoc(doc):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in doc]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "  return tokens\n",
        "\n",
        "def cnvStrToList(data):\n",
        "  for i in  range(len(data)):\n",
        "    if(data[i][-1]==\"]\"):\n",
        "      data[i]=eval(data[i])\n",
        "    else:\n",
        "      data[i]=eval(data[i]+\"]\")\n",
        "  return data\n",
        "\n",
        "userTokenMap={}\n",
        "def getVocab(data):\n",
        "  l=[]\n",
        "  global userTokenMap\n",
        "  maxLen=0\n",
        "  for row in data:\n",
        "    l.extend(row)\n",
        "  l=list(set(l))\n",
        "  l.sort()\n",
        "  userTokenMap={ele:i+1 for i,ele in enumerate(l)}\n",
        "  return len(l)\n",
        "\n",
        "userReviews=[cleanDoc(ele) for ele in cnvStrToList(userReviews)]\n",
        "foodReviews=[ele for ele in cnvStrToList(foodReviews)]\n",
        "\n",
        "userMaxLen=len(max(userReviews,key=lambda x:len(x)))\n",
        "userVocab=getVocab(userReviews)\n",
        "\n",
        "foodMaxLen=1405\n",
        "foodVocab=1405\n",
        "flavanoids=[]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNad7d6nSKo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "30df6d48-48f3-4fe8-937d-643ef6d001b2"
      },
      "source": [
        "print(list(flavanoidDB.values())[0])\n",
        "foodTokenMap={}\n",
        "l=[]\n",
        "for ele in list(flavanoidDB.values()):\n",
        "  l.extend(eval(ele))\n",
        "l=list(set(l))\n",
        "l.sort()\n",
        "print(l[0])\n",
        "print(len(l[0]))\n",
        "foodTokenMap={ele:i+1 for i,ele in enumerate(l)}\n",
        "print(len(foodTokenMap))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ethyl-Lactate', '3,4-Dihydroxybenzaldehyde', 'DL-Liquiritigenin', '2-Acetylpyrrole', 'benzaldehyde', 'Ethyl-Vinyl-Ketone', '5-Hydroxymethylfurfural', '2,3,5-Trimethylpyrazine', 'Octan-2-ol', '2-Butanone', 'coumarin', 'indole', 'CHEBI:49249', 'Isobutyl-isothiocyanate', '2-Isobutyl-3-Methoxypyrazine', 'Allyl-methyl-sulfide', 'Humulene', 'AC1L9CNW', 'Vitamin-U', 'Alpha-Terpinyl-Acetate', 'S-Propyl-thioacetate', 'Terpinen-4-ol', 'Isobornyl-acetate', 'Phlorizin', 'Methyl-tetradecanoate', '(Z)-Hex-3-en-1-ol', '.alpha.-Calacorene', 'Tetrasulfide,-dimethyl', 'M-Cymene', '(-)-Epicatechin-gallate', 'Methyleugenol', '2-Nonanol', 'cinnamaldehyde', '2-Hexanone', 'Valencene', '2-Methylbutyraldehyde', '3,5-Diethyl-1,2,4-trithiolane', 'Isobutyl-Acetate', 'Coumestrol', 'Ocimene', 'farnesol', 'Citral', '2-isopropyl-6-methoxypyrazine', 'hydrogen-cyanide', 'Ethyl-Propyl-Disulfide', 'Methyl-propyl-disulfide', '2-Mercapto-2-Methyl-1-Pentanol', 'Hexanal', 'Damascenone', '2,3-butanedione', '1,3-Dithiane', '3,4-Dimethylphenol', 'Heptanal', 'Propyl-sulfide', 'trans,trans-2,4-Nonadienal', 'trans-2-Nonenal', 'Ethyl-Acetate', 'gamma-Caprolactone', 'D-Lactic-acid', 'Tetradecanoic-acid', '3-Octanone', 'Isobutyl-Formate', 'hydrogen-sulfide', 'Isovaleric-Acid', 'cis-Jasmone', 'D-mannitol', '156420-69-8', 'Cianidanol', 'Methyl-Benzoate', 'Eucalyptol', 'Pentanal', 'Propenyl-propyl-disulfide', 'Methyl-Stearate', 'Allyl-Mercaptan', 'Curcumenol', 'Linalool', 'alpha-Cadinene', 'Menthone', 'palmitic-acid', 'Diallyl-trisulfide', 'Pyridine', '1-Dodecanol', 'Ethyl-Benzoate', 'Hexyl-acetate', 'Nerolidyl-acetate', 'indole-3-acetic-acid', '2-Acetyl-2-thiazoline', '2,6-Dimethylpyrazine', '3-Methylcyclopentane-1,2-dione', 'Nonanal', 'Tributyrin', 'Pyruvic-acid', 'Terpinolene', 'UNII-M41Y60O5BZ', '4-Methyl-5-Thiazoleethanol', 'Isoquercitrin', '2-Phenylethanol', 'Linalyl-Acetate', 'Diisopropyl-trisulfide', 'Gamma-Terpinene', 'Diallyl-Disulfide', '3-Phenylpropanoic-acid', 'Beta-Phellandrene', 'phloretin', 'Carvacrol', 'Curcumene', 'dimethyl-sulfide', 'Ethyl-Formate', '2,6-Dimethoxyphenol', 'carnosol', 'Disulfide,-methyl-1-propenyl', '1-octanol', '2-Isopropyl-5-methylcyclohexanone', 'Beta-Caryophyllene', 'Neral', '1-Propanethiol', 'Phytol', '1-Octen-3-Ol', 'daidzein', 'Methyl-octanoate', 'nan', 'cis-Isoeugenol', 'Alpha-Ionone', 'Dipropyl-trisulfide', 'Daidzin', 'Beta-Pinene', 'Allyl-Methyl-Disulfide', 'Isopentyl-formate', '2-Acetyl-5-Methylfuran', '2-Methyl-2-Pentenal', '(Z)-cinnamyl-alcohol', '2-Heptanone', 'sulfur-dioxide', 'Dipentene', 'Methyl-Acetate', '2-Methyl-1-propanol', 'methanethiol', 'Sinapic-Acid', 'Isoamyl-Acetate', 'quercetin', 'L-Rhamnose', 'isopropanol', '2-Pentanol', '2-Methyl-1-Butanol', '3-Carene', '2-Isopropyl-3-Methoxypyrazine', 'Vanillic-acid', 'Furfuryl-acetate', '2,3-Pentanedione', '.alpha.-Cubebene', '2-Heptanol', '(-)-Zingiberene', 'butein', '24168-70-5', '2-Nonanone', 'calcium-lactate', '3-Hexanone', '(-)-gamma-cadinene', 'hydrogen-peroxide', '(5xi,7xi,10xi)-eudesma-4(14),11-diene', 'S-allyl-L-cysteine', 'Methyl-propyl-trisulfide', 'gamma-Decalactone', '(-)-Epigallocatechin', 'gamma-Butyrolactone', 'methyl-(9E,12Z)-octadeca-9,12-dienoate', '4-Methyl-5-Vinylthiazole', '3-methylthiopropanol', '2-(4-Hydroxyphenyl)ethanol', 'Tangeretin', 'gamma-Nonanolactone', 'Cyclopentanone', 'Carvone', '(Z)-Ethyl-cinnamate', 'methyl-salicylate', '6-Methyl-5-Hepten-2-One', 'Tiglic-aldehyde', '2,3-Dimethylbenzofuran', 'D-Isoleucine-Methyl-Ester-Hydrochloride', 'D-Camphor', 'betaine', 'P-Cymene', '4-Methyl-2-pentanone', '(+)-alpha-Terpineol', '2-Methyltetrahydrofuran-3-One', '3-Pentanone', 'Cinnamic-Acid', '4-isopropylbenzaldehyde', 'Styrene', 'phenol', '2-Ethyl-4-hydroxy-5-methyl-3(2H)-furanone', 'Methyl-jasmonate', '(Z)-Hex-4-enal', 'resveratrol', '(+)-Camphene', 'Cubenol', '3-Ethyl-2,5-dimethylpyrazine', '1-Popc', 'acetic-acid', '2-Phenylethyl-formate', 'trans-Anethole', '2-Undecanol', 'succinic-acid', 'alpha-Cadinol', 'Dl-Methionine', 'salicylic-acid', 'Isobutyraldehyde', '3-Thujene', 'CID-644104', '1,3-Diphenyl-1-butanone', 'Gallocatechin', 'dibutyl-phthalate', 'Geraniol', 'Acrolein', '5-Methylfurfural', 'D-Limonene', 'Isopentyl-benzoate', 'Thiamine-Hydrochloride', '2,5-Dimethylthiophene', '(+)-Neomenthol', 'l-.alpha.-Cadinol', '2-Methylbutyl-Acetate', 'Isoborneol', '1-(4-Methylphenyl)ethanol', '3-Mercapto-2-methylpentanal', '3-Methyl-2-Cyclopenten-1-One', 'Benzyl-Salicylate', '(+)-delta-Cadinene', 'Octanal', 'Acetal', '3-Methylbutanal', 'Ethyl-Cinnamate', 'Beta-Ionone', 'Acetyleugenol', 'cis-Cinnamic-acid', '3-Methyl-2-butenal', '3-Methoxybenzaldehyde', 'octanoic-acid', 'benzyl-isothiocyanate', 'Ethyl-Octanoate', '2-Pentyl-Acetate', '33368-82-0', 'Isopropyl-Acetate', 'eugenol', 'guaiacol', '2-amino-3-(prop-2-en-1-ylsulfanyl)propanoic-acid', 'UNII-H5E892YJGG', 'Phenylacetic-Acid', '2-Pentanone', 'Undecanoic-Acid', 'Pyrrolidine', 'Allyl-propyl-sulfide', 'benzoic-acid', 'DL-Tartaric-acid', 'Benzyl-tiglate', 'Linamarin', '3,4-Dihydroxybenzoic-Acid', '2-Methoxy-4-vinylphenol', '3242-08-8', 'Acetophenone', '4-Hexen-1-Ol', '2-Methylbenzaldehyde', 'Nerolidol', '2-Furylacetone', 'Farnesal', 'Butyl-propyl-disulfide', '2-Acetylthiazole', 'Maltol', 'naringenin', '1-Pyrroline', '2,5-Dimethylpyrazine', 'Alpha-Terpinene', 'Dimethyl-disulfide', 'propionic-acid', '.beta.-Bourbonene', 'trans-2-Hexen-1-Ol', 'Dipropyl-disulfide', '2,6-Di-tert-butyl-4-methylphenol', 'NSC5112', '1-Methylnaphthalene', 'Hexanoic-Acid', 'Alpha-Pinene', 'Phenethyl-acetate', '2-Methylpyrazine', 'Aromadendrene', '6753-98-6', '(E)-gamma-Bisabolene', 'Ethyl-Levulinate', 'trans-3-Hexen-1-ol', 'Borneol', 'Beta-Selinene', '1-Nonanol', 'Beta-Elemene', 'Taxifolin', 'Myrcene', '1-Hexanol', 'Caryophyllene', 'Juniper-camphor', 'Allyldimethylsilane', '4-Vinylphenol', 'Octan-2-one', '1-Phenylethyl-acetate', 'Furfuryl-Alcohol', 'Ethyl-caproate', 'lauric-acid', 'kaempferol', 'Camphene', '4-Hexen-3-One', 'Thymol', 'Isoeugenol', 'isoliquiritigenin', '2,3,5,6-Tetramethylpyrazine', 'Allyl-Alcohol', '3-Hexanol', 'ethanol', 'alpha-Muurolene', '227456-27-1', '2-Methylpentanal', 'caftaric-acid', '3-Methyl-2-Butanol', '(-)-Epicatechin', 'Allyl-Isothiocyanate', 'Thymol-methyl-ether', 'cis-3-Hexenal', 'acetone', '(-)-Limonene', '3-Methyl-2-Buten-1-Ol', 'Beta-Terpineol', 'p-coumaric-acid', 'Clove-Oil', '4-hydroxybenzaldehyde', 'S-Methyl-thioacetate', 'alpha-TERPINEOL', 'D-Fenchone', 'Estragole', '3-Heptanone', '7-methyl-4-methylidene-1-propan-2-yl-2,3,4a,5,6,8a-hexahydro-1H-naphthalene', '2-Furaldehyde', 'gingerol', 'Dl-Phenylalanine', 'Methyl-propenyl-ketone', '(-)-Epigallocatechin-gallate', 'Acetovanillone', '(E)-Hept-2-enal', 'apigenin', 'vanillin', '3-Methyl-2-Cyclohexen-1-One', 'Diallyl-Sulfide', 'Dimethyl-trisulfide', 'Alpha-Phellandrene', 'luteolin', '1-propanol', 'phenylacetaldehyde', '(+)-alpha-phellandrene', 'Propyl-butyrate', 'Benzyl-Acetate', '3-Methyl-1-butanol', '1-Phenylethanol', 'Benzyl-Benzoate', 'Isobutyl-butyrate', '2-Acetylpyridine', '4-isopropylbenzyl-alcohol', 'Isorhamnetin', '1-Penten-3-Ol', '2-Pentylfuran', 'L-histidine', 'Propyl-acetate', 'Chavicol', 'AC1NST8Q', 'Syringaldehyde', 'Nonanoic-Acid', '2-Undecanone', 'nicotine', '.beta.-Sesquiphellandrene', 'Sabinene-hydrate', 'Methyl-Palmitate', 'Neryl-propionate', 'cinnamyl-alcohol', 'Piperitol', 'cis-3-Hexenyl-acetate', 'Geranyl-Acetate', 'Allyl-Propyl-Disulfide', '(+)-gamma-cadinene', 'naphthalene', '2-Methylbutanoic-acid', 'benzyl-alcohol', 'alpha-Maltose', 'alpha-L-Sorbopyranose', 'Ethyl-Butyrate', 'Heptanoic-Acid', 'thiamine', 'Allyl-Methyl-Trisulfide', '2-Tridecanone', 'L-phenylalanine', 'Propionaldehyde', '3-(Methylthio)propionaldehyde', 'Caryophyllene-oxide', 'Diallyl-tetrasulfide', 'dimethyl-sulfoxide', 'Propyl-Benzoate']\n",
            "(+)-Camphene\n",
            "12\n",
            "1405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BreRANibP_OB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c746bb6b-730d-4dc6-8aa7-48adcd066e9c"
      },
      "source": [
        "print(userMaxLen)\n",
        "print(userVocab)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186\n",
            "8613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XajcygmQfVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6d391193-b5ef-4541-aafe-143472a0cdf7"
      },
      "source": [
        "print(list(userTokenMap.keys())[0])\n",
        "print(list(foodTokenMap.keys())[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aadding\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz3yvYhhQcqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "userReviews=[\" \".join(ele) for ele in userReviews]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKuryUu4RBxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b630000d-a431-490d-de89-ea745a99d1b6"
      },
      "source": [
        "modFoodReviews=[]\n",
        "for ele in foodReviews:\n",
        "  modFoodReviews.append(\" \".join(flv.replace(\" \",\"-\") for flv in ele))\n",
        "print(modFoodReviews[0])\n",
        "foodReviews=modFoodReviews"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4-Hexen-3-One Mesityl-Oxide 3-Phenylpropanoic-acid succinic-acid 1-Heptanol Isoeugenol 3,4-Dihydroxybenzaldehyde salicylic-acid Isobutyl-mercaptan phloretin 23726-92-3 Isobutyraldehyde isoliquiritigenin Allyl-Alcohol DL-Liquiritigenin 2-Acetylpyrrole dimethyl-sulfide benzaldehyde Ethyl-Vinyl-Ketone Ethyl-3-hydroxyhexanoate Ethyl-dodecanoate CID-644104 2,3,5-Trimethylpyrazine DL-Valine Gallocatechin 2-Butanone 1-octanol 2-Isopropyl-5-methylcyclohexanone Tetradecanal 2-Methylpentanal taurine Geraniol Acrolein trans-2-Hexenal Ethyl-Nonanoate coumarin indole L-lysine Thiamine-Hydrochloride Neral 3-Methylindole 2'-Hydroxyacetophenone (+)-Neomenthol (-)-Epicatechin Allyl-Isothiocyanate daidzein (-)-beta-Pinene Alpha-Ionone cis-3-Hexenal Daidzin Beta-Pinene butyraldehyde acetone (Z)-cinnamyl-alcohol 3-Methyl-2-Buten-1-Ol 2-Heptanone Terpinyl-propionate Vitamin-U p-coumaric-acid delta-Undecalactone (+)-delta-Cadinene L-Lactic-acid Octanal 3-Methylbutanal 4-hydroxybenzaldehyde Undecanal alpha-TERPINEOL Phlorizin Beta-Ionone 2-Methyl-1-propanol methanethiol Acetylpyrazine P-Cresol Perillaldehyde (-)-Epicatechin-gallate delta-Tetradecalactone Sinapic-Acid Delta-Dodecalactone cinnamaldehyde Isoamyl-Acetate L-aspartic-acid quercetin Valencene 2-Methylbutyraldehyde (-)-alpha-Pinene 2-Furaldehyde 3-Methyl-2-butenal isopropanol 2-Undecanol octanoic-acid Methyl-Hexanoate (-)-Epigallocatechin-gallate 6-methyl-2-(oxiran-2-yl)hept-5-en-2-ol Isoquinoline 2-Methyl-1-Butanol trans-2-Dodecenal farnesol Citral Vanillic-acid vanillin apigenin Furfuryl-acetate Dimethyl-trisulfide Alpha-Phellandrene luteolin phenylacetaldehyde 2,3-Pentanedione hydrogen-cyanide Propyl-butyrate 1-Furfurylpyrrole Hexanal 2,3-butanedione Methyl-butyrate Phenylacetic-Acid 3-Methyl-1-butanol 2-Pentanone Pyrazine Benzyl-Benzoate Heptanal 2-Nonanone lactic-acid calcium-lactate Ethyl-Acetate gamma-Caprolactone D-Lactic-acid Pyrrolidine Tetradecanoic-acid 3-Hexanone Isorhamnetin hydrogen-sulfide hydrogen-peroxide Isovaleric-Acid L-histidine Linamarin 3,4-Dihydroxybenzoic-Acid D-mannitol gamma-Decalactone gamma-Dodecalactone (-)-Epigallocatechin Cianidanol 1-Decanol Methyl-Benzoate Syringaldehyde Nonyl-Acetate Eucalyptol 5,6-dimethyloxan-2-one Pentanal 3-methylthiopropanol 5-Methylquinoxaline 2-(4-Hydroxyphenyl)ethanol Nonanoic-Acid 2-Undecanone nicotine 2-Ethylbutanal Nerolidol (2E,4E)-deca-2,4-dienal gamma-Nonanolactone Cyclopentanone Farnesal cinnamyl-alcohol Piperitenone 2-Undecenal 1-Undecanol 50-69-1 Linalool Decanoic-acid cis-3-Hexenyl-acetate 104-50-7 Maltol naringenin 1-Octen-3-One 1-Pyrroline Geranyl-Acetate Ethyl-2-methylbutyrate 6-Methyl-5-Hepten-2-One Tiglic-aldehyde Dimethyl-disulfide Menthone propionic-acid palmitic-acid trans-2-Hexen-1-Ol NSC5112 benzyl-alcohol Ethyl-Heptanoate 1-Methylnaphthalene Methyl-2-furoate betaine alpha-Maltose l-ascorbic-acid P-Cymene Violet-leaf-aldehyde butyric-acid 4-Methyl-2-pentanone 3658-77-3 3-Pentanone Alpha-Pinene Hexanoic-Acid Pyridine alpha-L-Sorbopyranose Phenethyl-acetate 2-Methylpyrazine Cinnamic-Acid 23747-48-0 Heptanoic-Acid Ethyl-Butyrate Delta-Decalactone thiamine Ethyl-Benzoate trans-3-Hexen-1-ol Hexyl-acetate phenol Styrene formic-acid Pyrrole Phenethylamine indole-3-acetic-acid 2-Tridecanone 2-Ethyl-4-hydroxy-5-methyl-3(2H)-furanone 1-Nonanol 3-Methylcyclopentane-1,2-dione Propionaldehyde Tributyrin 3-(Methylthio)propionaldehyde Methyl-jasmonate Nonanal Decanal nerol Methyl-Linoleate Taxifolin Myrcene Pyruvic-acid Terpinolene 1-Hexanol Ethyl-Decanoate Dodecanal Octan-2-one Bis(methylthio)methane Linalyl-Acetate Isoquercitrin 2-Phenylethanol Furfuryl-Alcohol Prunin lauric-acid Gamma-Terpinene kaempferol dimethyl-sulfoxide\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmmKN9duRb6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encodeToOneHot(data,vocab):\n",
        "  l=[]\n",
        "  for ele in data:\n",
        "    if(ele in vocab.keys()):\n",
        "      l.append(vocab[ele])\n",
        "    else:\n",
        "      l.append(0)\n",
        "  return l\n",
        "\n",
        "encoded_userReviews=[encodeToOneHot(d,userTokenMap) for d in userReviews]\n",
        "encoded_foodReviews=[encodeToOneHot(d,foodTokenMap) for d in foodReviews]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyFrRhDfRvyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "57b0bfe0-2f3f-4487-f022-80c8bd84abd6"
      },
      "source": [
        "print(encoded_userReviews[0])\n",
        "print(encoded_foodReviews[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1988, 2345, 4385]\n",
            "[464, 970, 430, 1374, 96, 908, 360, 1371, 902, 1362, 350, 906, 1323, 566, 702, 216, 1290, 1224, 799, 772, 802, 650, 154, 704, 833, 219, 127, 260, 1158, 297, 1376, 840, 562, 1387, 789, 1281, 1321, 946, 1165, 1032, 420, 149, 5, 15, 567, 1284, 26, 577, 1255, 705, 616, 1242, 1207, 60, 407, 245, 1157, 1197, 1357, 1288, 9, 938, 1054, 415, 492, 1185, 1220, 1090, 614, 275, 1333, 559, 1062, 1076, 16, 1287, 1147, 714, 1249, 883, 943, 1366, 1189, 293, 24, 241, 410, 1324, 334, 1349, 995, 18, 535, 932, 273, 1385, 1299, 674, 1192, 1405, 1222, 826, 741, 579, 1331, 1361, 164, 1317, 1111, 95, 863, 166, 1007, 1088, 404, 312, 1118, 598, 856, 304, 1329, 1246, 776, 1303, 698, 1121, 1160, 393, 933, 1319, 1318, 934, 945, 960, 361, 701, 1304, 1305, 17, 670, 93, 992, 1151, 1045, 814, 502, 1070, 435, 516, 202, 1043, 335, 1345, 234, 1034, 37, 1309, 694, 816, 1250, 1094, 336, 125, 519, 952, 710, 1256, 135, 966, 1342, 109, 122, 841, 767, 528, 1172, 739, 968, 1364, 1358, 1386, 1029, 1226, 784, 106, 978, 1240, 1218, 1328, 1063, 1196, 1243, 478, 441, 427, 580, 865, 1119, 1217, 1081, 299, 672, 351, 858, 779, 713, 1378, 778, 1398, 869, 1360, 1150, 1300, 1120, 1086, 1322, 333, 231, 107, 418, 1102, 1173, 378, 1012, 1041, 708, 1344, 998, 1153, 1024, 1122, 1155, 100, 782, 752, 1053, 621, 955, 931, 321, 825, 1116, 1330, 834, 1325, 1291]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9HFvXblR0yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_userReviews=pad_sequences(encoded_userReviews,maxlen=userMaxLen,padding=\"post\")\n",
        "padded_foodReviews=pad_sequences(encoded_foodReviews,maxlen=foodMaxLen,padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU8i60vUSK_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "6b430515-716b-4c77-b9b6-44220aeaacbc"
      },
      "source": [
        "print(type(padded_userReviews[0]))\n",
        "print(padded_userReviews[0])\n",
        "print(padded_foodReviews[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[1988 2345 4385    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "[464 970 430 ...   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDAkAMP_SRKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processedData[\"userReviews\"]=[str(ele) for ele in padded_userReviews.tolist()]\n",
        "processedData[\"foodReviews\"]=[str(ele) for ele in padded_foodReviews.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DRP1H-SIPAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train/test split for our model is unique, we need to hold out a\n",
        "# set of users and movies so that our network never learns those \n",
        "testSize = 0.005\n",
        "\n",
        "# get testSize percentage of users\n",
        "uniqueUsers = processedData.loc[:, \"user_id\"].unique()\n",
        "usersSize = len(uniqueUsers)\n",
        "test_idx = np.random.choice(usersSize,\n",
        "                              size=int(usersSize * testSize),\n",
        "                              replace=False)\n",
        "\n",
        "# get test users\n",
        "testUsers = uniqueUsers[test_idx]\n",
        "\n",
        "# everyone else is a training user\n",
        "trainUsers = np.delete(uniqueUsers, test_idx)\n",
        "\n",
        "test = processedData[processedData[\"user_id\"].isin(testUsers)]\n",
        "train = processedData[processedData[\"user_id\"].isin(trainUsers)]\n",
        "\n",
        "uniqueTestFood = test[\"food_id\"].unique()\n",
        "\n",
        "# drop the movies that also appear in our test set. In order to be\n",
        "# a true train/test split, we are forced to discard some data entirely\n",
        "train = train.where(np.logical_not(train[\"food_id\"].isin(uniqueTestFood))).dropna()\n",
        "train=shuffle(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2gb9Q4BYpms",
        "colab_type": "code",
        "outputId": "b61ed20f-9644-4dd6-a481-db66012ba0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43735</th>\n",
              "      <td>79835.0</td>\n",
              "      <td>16100.0</td>\n",
              "      <td>335</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[7336, 2345, 1988, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[787, 360, 216, 702, 799, 1224, 643, 509, 154,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25919</th>\n",
              "      <td>46677.0</td>\n",
              "      <td>13515.0</td>\n",
              "      <td>300</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[1988, 5396, 228, 6128, 6010, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[787, 524, 360, 216, 702, 799, 1224, 643, 509,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47149</th>\n",
              "      <td>86355.0</td>\n",
              "      <td>17027.0</td>\n",
              "      <td>95</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[74, 4245, 8110, 7187, 3120, 704, 2826, 5977, ...</td>\n",
              "      <td>[524, 360, 702, 1224, 799, 154, 1394, 219, 128...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13381</th>\n",
              "      <td>24852.0</td>\n",
              "      <td>16551.0</td>\n",
              "      <td>851</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[3173, 8060, 1278, 7187, 3770, 8256, 7488, 325...</td>\n",
              "      <td>[211, 787, 360, 902, 216, 702, 799, 1224, 643,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23291</th>\n",
              "      <td>41960.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>231</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[7492, 3252, 224, 3669, 3733, 559, 3367, 0, 0,...</td>\n",
              "      <td>[360, 1206, 702, 216, 1224, 799, 643, 509, 105...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                        foodReviews\n",
              "43735     79835.0  ...  [787, 360, 216, 702, 799, 1224, 643, 509, 154,...\n",
              "25919     46677.0  ...  [787, 524, 360, 216, 702, 799, 1224, 643, 509,...\n",
              "47149     86355.0  ...  [524, 360, 702, 1224, 799, 154, 1394, 219, 128...\n",
              "13381     24852.0  ...  [211, 787, 360, 902, 216, 702, 799, 1224, 643,...\n",
              "23291     41960.0  ...  [360, 1206, 702, 216, 1224, 799, 643, 509, 105...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ANBx5tnIvtR",
        "colab_type": "code",
        "outputId": "6c8253bf-ec03-4910-a538-3ebb3fd9a2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"train={} test={}\".format(train.shape,test.shape))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train=(15997, 6) test=(221, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGmlk4ZgTkkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f06265c7-71dd-441e-df8c-48bacb27fa92"
      },
      "source": [
        "print(type(train[\"userReviews\"][0]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3BRQ0uTI4rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainUserReviews=[eval(ele) for ele in train[\"userReviews\"].tolist()]\n",
        "testUserReviews=[eval(ele) for ele in test[\"userReviews\"].tolist()]\n",
        "\n",
        "trainFoodReviews=[eval(ele) for ele in train[\"foodReviews\"].tolist()]\n",
        "testFoodReviews=[eval(ele) for ele in test[\"foodReviews\"].tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKt0GMiJLaAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"Embedding Dimensions => userReviews={} || foodReviews={}\".format(trainUserReviews.shape,trainFoodReviews.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3TjSeG5MAzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "class DeepCoNN():\n",
        "    def __init__(self,\n",
        "                 userEmbeddingSize,\n",
        "                 foodEmbeddingSize,\n",
        "                 userMaxLength,\n",
        "                 foodMaxLength,\n",
        "                 hiddenSize,\n",
        "                 filters=100,\n",
        "                 kernelSize=3,\n",
        "                 strides=1):\n",
        "        self.userEmbeddingSize = userEmbeddingSize\n",
        "        self.foodEmbeddingSize=foodEmbeddingSize\n",
        "        self.hiddenSize = hiddenSize\n",
        "        self.filters = filters\n",
        "        self.kernelSize = kernelSize\n",
        "        self.userMaxLength=userMaxLength\n",
        "        self.foodMaxLength=foodMaxLength\n",
        "        self.inputU, self.towerU = self.createDeepCoNnTower(self.userEmbeddingSize,self.userMaxLength)\n",
        "        self.inputF, self.towerF = self.createDeepCoNnTower(self.foodEmbeddingSize,self.foodMaxLength)\n",
        "        self.joined = Concatenate()([self.towerU, self.towerF])\n",
        "        self.outNeuron = Dense(1)(self.joined)\n",
        "\n",
        "    def createDeepCoNnTower(self,embeddingSize,maxLength):\n",
        "        inputLayer = Input(shape=(maxLength,))\n",
        "        embeddingLayer=Embedding(embeddingSize,300,input_length=maxLength)(inputLayer)\n",
        "        tower = Conv1D(filters=self.filters,\n",
        "                       kernel_size=self.kernelSize,\n",
        "                       kernel_initializer='random_uniform',activation=\"tanh\")(embeddingLayer)\n",
        "        # tower=LeakyReLU(alpha=0.05)(tower)\n",
        "        tower = MaxPooling1D()(tower)\n",
        "        tower = Flatten()(tower)\n",
        "        tower = Dense(self.hiddenSize,activation=\"tanh\",kernel_initializer='random_uniform')(tower)\n",
        "        # tower=LeakyReLU(alpha=0.05)(tower)\n",
        "        return inputLayer, tower\n",
        "\n",
        "    def createDeepCoNnDp(self):\n",
        "        # dotproduct = Dot(axes=1)([self.towerU, self.towerF])\n",
        "        # output = Add()([self.outNeuron, dotproduct])\n",
        "        output=self.outNeuron\n",
        "        self.model = Model(inputs=[self.inputU, self.inputF], outputs=[output])\n",
        "        opt=optimizers.Adadelta()\n",
        "        self.model.compile(optimizer=opt, loss='mse')\n",
        "        \n",
        "    def train(self, trainData,trainUserReviews,trainFoodReviews, batch_size, epochs=1):\n",
        "        tensorboard = TensorBoard(log_dir=\"tf_logs/{}\".format(pd.Timestamp(int(time()), unit=\"s\")))\n",
        "        self.createDeepCoNnDp()\n",
        "        print(self.model.summary())\n",
        "        \n",
        "        # userReviews = np.array(trainData.loc[:, \"userReviews\"])\n",
        "        # foodReviews = np.array(trainData.loc[:, \"foodReviews\"])\n",
        "        userReviews=trainUserReviews\n",
        "        foodReviews=trainFoodReviews\n",
        "\n",
        "        self.train_inputs = [userReviews, foodReviews]\n",
        "        self.train_outputs = trainData.loc[:, \"rating\"]\n",
        "        \n",
        "        self.history = self.model.fit(self.train_inputs,\n",
        "                                      self.train_outputs,\n",
        "                                      callbacks=[tensorboard],\n",
        "                                      validation_split=0.05,\n",
        "                                      batch_size=batch_size,\n",
        "                                      epochs=epochs)\n",
        "        self.model_json=self.model.to_json()\n",
        "        with open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/EmbeddedRsModelArchi.json\",\"w\") as json_file:\n",
        "          json_file.write(self.model_json)\n",
        "          print(\"model architecture saved\")\n",
        "          self.model.save_weights(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/EmbeddedRs.h5\")\n",
        "          print(\"saved model to disk\")\n",
        "          \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCEiaBGRqN3",
        "colab_type": "code",
        "outputId": "164c49b5-dfbd-48ba-e351-8a50ac65dd71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        }
      },
      "source": [
        "hiddenSize = 50\n",
        "\n",
        "deepconn = DeepCoNN(userEmbeddingSize=userVocab,foodEmbeddingSize=foodVocab+1,hiddenSize=hiddenSize,userMaxLength=userMaxLen,foodMaxLength=foodMaxLen)\n",
        "\n",
        "batch_size = 100\n",
        "deepconn.train(train,trainUserReviews,trainFoodReviews, batch_size, epochs=1)\n",
        "\n",
        "deepconn.model.save(\"cnn.h5\")\n",
        "# print(train_embedded.loc[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 186)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1405)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 186, 300)     2583900     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1405, 300)    421800      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 184, 100)     90100       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1403, 100)    90100       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 92, 100)      0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 701, 100)     0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 9200)         0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 70100)        0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 50)           460050      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 50)           3505050     flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 100)          0           dense_4[0][0]                    \n",
            "                                                                 dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            101         concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 7,151,101\n",
            "Trainable params: 7,151,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 15197 samples, validate on 800 samples\n",
            "Epoch 1/1\n",
            "15197/15197 [==============================] - 348s 23ms/step - loss: 1.2892 - val_loss: 0.6695\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "model architecture saved\n",
            "saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rotX_tNNSKra",
        "colab_type": "code",
        "outputId": "de715b1d-19f3-4d5e-a45e-436a7a3bb0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "testInputs = [testUserReviews, testFoodReviews]\n",
        "#print(testInputs)\n",
        "# dat = pd.DataFrame(testInputs)\n",
        "# dat.to_csv(\"/content/gdrive/My Drive/DeepConn/Deep_Learning_Recommender_System//test_data.csv\")\n",
        "\n",
        "trueRating = np.array(list(test.loc[:, \"rating\"])).reshape((-1, 1))\n",
        "\n",
        "predictions = deepconn.model.predict(testInputs)\n",
        "print(predictions)\n",
        "error = np.square(predictions - trueRating)\n",
        "\n",
        "print(\"MSE:\", np.average(error))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.46235  ]\n",
            " [4.47468  ]\n",
            " [4.4195457]\n",
            " [4.5282016]\n",
            " [4.419279 ]\n",
            " [4.5279346]\n",
            " [4.419279 ]\n",
            " [4.4627   ]\n",
            " [4.7853303]\n",
            " [4.836211 ]\n",
            " [4.391779 ]\n",
            " [4.4196815]\n",
            " [4.4625354]\n",
            " [4.6962843]\n",
            " [4.419486 ]\n",
            " [4.6026525]\n",
            " [4.419353 ]\n",
            " [4.5280085]\n",
            " [4.6634607]\n",
            " [4.796725 ]\n",
            " [4.4628897]\n",
            " [4.5280848]\n",
            " [4.704015 ]\n",
            " [4.462951 ]\n",
            " [4.6854606]\n",
            " [4.4628124]\n",
            " [4.69207  ]\n",
            " [4.66298  ]\n",
            " [4.8356185]\n",
            " [4.293719 ]\n",
            " [4.678683 ]\n",
            " [4.500838 ]\n",
            " [4.528152 ]\n",
            " [4.539673 ]\n",
            " [4.4194365]\n",
            " [4.6872325]\n",
            " [4.4182577]\n",
            " [4.46277  ]\n",
            " [4.634836 ]\n",
            " [4.4628663]\n",
            " [4.568911 ]\n",
            " [4.414134 ]\n",
            " [4.568898 ]\n",
            " [4.7842107]\n",
            " [4.785607 ]\n",
            " [4.2778025]\n",
            " [4.6636686]\n",
            " [4.7304187]\n",
            " [4.527304 ]\n",
            " [4.5603323]\n",
            " [4.620201 ]\n",
            " [4.6631136]\n",
            " [4.6849027]\n",
            " [4.487397 ]\n",
            " [4.7303233]\n",
            " [4.4196677]\n",
            " [4.5978713]\n",
            " [4.4612617]\n",
            " [4.7145224]\n",
            " [4.677519 ]\n",
            " [4.469784 ]\n",
            " [4.4615874]\n",
            " [4.603231 ]\n",
            " [4.624555 ]\n",
            " [4.3182926]\n",
            " [4.463018 ]\n",
            " [4.273996 ]\n",
            " [4.6866527]\n",
            " [4.637634 ]\n",
            " [4.728417 ]\n",
            " [4.7301316]\n",
            " [4.534834 ]\n",
            " [4.461155 ]\n",
            " [4.5677743]\n",
            " [4.6522965]\n",
            " [4.8352566]\n",
            " [4.462779 ]\n",
            " [4.495263 ]\n",
            " [4.3559976]\n",
            " [4.4628305]\n",
            " [4.647355 ]\n",
            " [4.6627502]\n",
            " [4.647974 ]\n",
            " [4.536361 ]\n",
            " [4.4626822]\n",
            " [4.785313 ]\n",
            " [4.5978827]\n",
            " [4.6637874]\n",
            " [4.4628973]\n",
            " [4.6634088]\n",
            " [4.785468 ]\n",
            " [4.537246 ]\n",
            " [4.41701  ]\n",
            " [4.6482477]\n",
            " [4.663643 ]\n",
            " [4.6745167]\n",
            " [4.796692 ]\n",
            " [4.46305  ]\n",
            " [4.462782 ]\n",
            " [4.450836 ]\n",
            " [4.614832 ]\n",
            " [4.6743674]\n",
            " [4.6147804]\n",
            " [4.559612 ]\n",
            " [4.4627867]\n",
            " [4.608399 ]\n",
            " [4.463647 ]\n",
            " [4.5280404]\n",
            " [4.528185 ]\n",
            " [4.4627485]\n",
            " [4.463036 ]\n",
            " [4.6856837]\n",
            " [4.581102 ]\n",
            " [4.8363614]\n",
            " [4.5688086]\n",
            " [4.430977 ]\n",
            " [4.4138246]\n",
            " [4.462234 ]\n",
            " [4.4622965]\n",
            " [4.490552 ]\n",
            " [4.418125 ]\n",
            " [4.5121384]\n",
            " [4.418924 ]\n",
            " [4.629922 ]\n",
            " [4.4591765]\n",
            " [4.8552275]\n",
            " [4.469971 ]\n",
            " [4.3948674]\n",
            " [4.46277  ]\n",
            " [4.65596  ]\n",
            " [4.4896665]\n",
            " [4.490922 ]\n",
            " [4.4628773]\n",
            " [4.687327 ]\n",
            " [4.464145 ]\n",
            " [4.5587564]\n",
            " [4.687318 ]\n",
            " [4.6782784]\n",
            " [4.4352293]\n",
            " [4.696258 ]\n",
            " [4.6635575]\n",
            " [4.6635575]\n",
            " [4.4628706]\n",
            " [4.7855015]\n",
            " [4.5034122]\n",
            " [4.6635404]\n",
            " [4.493513 ]\n",
            " [4.4630804]\n",
            " [4.4196715]\n",
            " [4.597983 ]\n",
            " [4.4192142]\n",
            " [4.4626346]\n",
            " [4.6634984]\n",
            " [4.4620824]\n",
            " [4.5738616]\n",
            " [4.677596 ]\n",
            " [4.4952397]\n",
            " [4.543441 ]\n",
            " [4.6481876]\n",
            " [4.6990566]\n",
            " [4.463002 ]\n",
            " [4.6028733]\n",
            " [4.7854743]\n",
            " [4.4627786]\n",
            " [4.4622884]\n",
            " [4.8545322]\n",
            " [4.678135 ]\n",
            " [4.6975484]\n",
            " [4.686325 ]\n",
            " [4.418612 ]\n",
            " [4.463069 ]\n",
            " [4.6807694]\n",
            " [4.419505 ]\n",
            " [4.635135 ]\n",
            " [4.662778 ]\n",
            " [4.416101 ]\n",
            " [4.461553 ]\n",
            " [4.6248426]\n",
            " [4.778437 ]\n",
            " [4.568078 ]\n",
            " [4.6031604]\n",
            " [4.418967 ]\n",
            " [4.461196 ]\n",
            " [4.600396 ]\n",
            " [4.778634 ]\n",
            " [4.5805535]\n",
            " [4.527235 ]\n",
            " [4.516405 ]\n",
            " [4.568643 ]\n",
            " [4.4848337]\n",
            " [4.7083335]\n",
            " [4.5282187]\n",
            " [4.604862 ]\n",
            " [4.419376 ]\n",
            " [4.43195  ]\n",
            " [4.4629087]\n",
            " [4.6635957]\n",
            " [4.46298  ]\n",
            " [4.4588156]\n",
            " [4.6637893]\n",
            " [4.463102 ]\n",
            " [4.7854958]\n",
            " [4.458825 ]\n",
            " [4.6838336]\n",
            " [4.417765 ]\n",
            " [4.648161 ]\n",
            " [4.62442  ]\n",
            " [4.4938426]\n",
            " [4.6637406]\n",
            " [4.6637406]\n",
            " [4.6637406]\n",
            " [4.4182916]\n",
            " [4.686004 ]\n",
            " [4.4410195]\n",
            " [4.4196763]\n",
            " [4.66995  ]\n",
            " [4.4618936]\n",
            " [4.7842517]\n",
            " [4.6636887]\n",
            " [4.4196925]\n",
            " [4.679523 ]]\n",
            "MSE: 0.5012649407814195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEA0LPy4j3Tg",
        "colab_type": "code",
        "outputId": "b71d3d84-863f-4366-dd9d-23ebbe7a3867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "\n",
        "\n",
        "#the funtion is needed when loading the vectorizer\n",
        "def dummy_fun(doc):\n",
        "  return doc\n",
        "\n",
        "\n",
        "class HealthScoreCalculator():\n",
        "  def __init__(self):\n",
        "    self.weights = {\n",
        "\t'normal' : {'calories' : 1, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1}, \n",
        "\t'diabetes' : {'calories' : 1, 'protein' : 1, 'sugar' : 4.25, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 3, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1},\n",
        "\t'bp' : {'calories' : 1, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 9, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1},\n",
        "\t'obesity' : {'calories' : 7, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1}\n",
        "\t}\n",
        "    self.predictedScores=None\n",
        "\n",
        "  def convToComStand(self,value):\n",
        "    if value.endswith('mg'):\n",
        "      value = value[:value.index('mg')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value) / 1000\n",
        "    elif value.endswith('g'):\n",
        "      value = value[:value.index('g')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value)\n",
        "    elif value.endswith('kcal'):\n",
        "      value = value[:value.index('kcal')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value)\n",
        "\n",
        "    elif value.endswith('IU'):\n",
        "      value = value[:value.index('IU')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = (float(value) / 3.3) / 1000000\n",
        "    \n",
        "    return value\n",
        "\n",
        "  def elixir(self,allowed, weights, bmratio, type = 'normal'):\n",
        "    weights = weights[type]\n",
        "    database = json.load(open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/database.json\", 'rb'))\n",
        "    x = {}\n",
        "    for dish in database:\n",
        "      dishId = dish['dish_id']\n",
        "      nutrients = dish['nutrients']\n",
        "      if all(nutrients.values()):\n",
        "        for nutrient in nutrients:\n",
        "          value = nutrients[nutrient]\n",
        "          if value:\n",
        "            #converting to  common standard\n",
        "            value = self.convToComStand(value[0])\n",
        "            nutrients[nutrient] = value\n",
        "        #################################\n",
        "        recbn = ['protein', 'dietary_fiber']\n",
        "        recbase = 0\n",
        "        for i in recbn:\n",
        "          recbase += weights[i] * nutrients[i] / allowed[i]\n",
        "\n",
        "        part1 = 0\n",
        "        part2 = 0\n",
        "        if nutrients['carbs']:\n",
        "          part1 = weights['dietary_fiber'] * nutrients['dietary_fiber'] / nutrients['carbs']\n",
        "          part2 =  0.1 * (nutrients['carbs'] - nutrients['dietary_fiber'] - nutrients['sugar']) / nutrients['carbs']\n",
        "\n",
        "        recbase = recbase + part1 + part2\n",
        "        #################################\n",
        "        restbn = ['carbs', 'cholesterol', 'sodium', 'sat_fat', 'fat', 'sugar']\n",
        "        restbase = 0\n",
        "        for i in restbn:\n",
        "          restbase += weights[i] * nutrients[i] / allowed[i]\n",
        "\n",
        "        part1 = 0\n",
        "        part2 = 0\n",
        "        if nutrients['sugar'] and nutrients['carbs']:\n",
        "          part1 = weights['carbs'] * nutrients['sugar'] / nutrients['carbs']\n",
        "\n",
        "        if nutrients['sat_fat'] and nutrients['fat']:\n",
        "          part2 = weights['sat_fat'] * nutrients['sat_fat'] / nutrients['fat']\n",
        "        \n",
        "        restbase = part1 + part2\t\t\t\n",
        "        #################################\n",
        "        recan = ['vitamin_a', 'vitamin_c', 'calcium', 'iron']\n",
        "        recadd = 0\n",
        "        for i in recan:\n",
        "          recadd += weights[i] * nutrients[i] / allowed[i]\n",
        "        #################################\n",
        "\n",
        "        mult = bmratio\n",
        "        div = ((1 + mult) * restbase)\n",
        "        if div:\n",
        "          score = recbase + (mult * recadd) / div\n",
        "        else:\n",
        "          score = 0\n",
        "\n",
        "        x[dishId] = score\n",
        "    self.predictedScores=x\n",
        "    return x\n",
        "\n",
        "  def get_lat_long(self,ip_addr =\"me\"):\n",
        "    g = geocoder.ip(ip_addr)\n",
        "    return g.latlng\n",
        "\n",
        "  def get_temp(self,lat, lon):\n",
        "    owm = pyowm.OWM('9bb248641cc71b7ab1b7040317ec6ac9')\n",
        "    observation_list = owm.weather_around_coords(lat, lon)\n",
        "    tot_temp = 0\n",
        "    if observation_list != None:\n",
        "      for i in observation_list:\n",
        "        w = i.get_weather()\n",
        "        temp = w.get_temperature('fahrenheit')['temp']\n",
        "        tot_temp += temp\n",
        "\n",
        "      temp = tot_temp / len(observation_list)\n",
        "\n",
        "      return temp\n",
        "\n",
        "  def elevation(self,lat, lng):\n",
        "    loc = str(lat) + ',' + str(lng)\n",
        "    apikey = \"AIzaSyAd0cewCPnbRF_0082PULMybInWNhWgDjA\"\n",
        "    base_url = \"https://maps.googleapis.com/maps/api/elevation/json\"\n",
        "    params = dict()\n",
        "    params[\"locations\"] = str(loc)\n",
        "    params[\"key\"] = apikey\n",
        "    r = requests.get(base_url, params=params)\n",
        "    results = json.loads(r.text).get('results')\n",
        "    return 847\n",
        "    return results[0]['elevation']\n",
        "\n",
        "  def adaptive_daily_value(self,weight, height, gender, age, steps, height_travelled, bmratio):\n",
        "    latlong = self.get_lat_long()\n",
        "    temp = self.get_temp(*latlong)\n",
        "    altitude =self.elevation(*latlong)\n",
        "\n",
        "    allowed = {'calories' : 2079.35, 'protein' : 50, 'fat' : 70, 'sat_fat' : 24, 'carbs' : 310, 'sugar' : 30, 'dietary_fiber' : 30, 'sodium' : 2.3, 'cholesterol' : 300, 'vitamin_a' : 0.0008, 'vitamin_c' : 0.08, 'iron' : 0.0087, 'calcium' : 1}\n",
        "    \n",
        "    work = 9.8 * weight * height_travelled * 0.000239006 + weight * steps / 6000\n",
        "    \n",
        "    bmr = weight * 10 + 6.25 * height - 5 * age\n",
        "    if gender == 'm':\n",
        "      bmr += 5\n",
        "    else:\n",
        "      bmr -= 161\n",
        "\n",
        "    daily_cal = round(bmratio * bmr + work, 2)\n",
        "    if temp != None:\n",
        "      daily_cal = daily_cal * (1 + (85 - temp) / 800)\n",
        "\n",
        "      for i in allowed:\n",
        "        allowed[i] = allowed[i] * daily_cal / 2079.35\n",
        "\n",
        "    na_multi = 1 + 0.015 * (((temp - 32) * 0.56) - 23)\n",
        "    allowed['sodium'] = na_multi * allowed['sodium'] + (altitude / 1000) ** 2.5\n",
        "\n",
        "    return allowed\n",
        "  def calculateScore(self,height,weight,age,gender,condition,bmratio,steps, floors):\n",
        "    floors = floors * 10 * 3.28084\n",
        "    allowed = self.adaptive_daily_value(weight, height, gender, age, steps, floors, bmratio)\n",
        "    score = self.elixir(allowed, self.weights, bmratio, type = condition)\n",
        "    return score\n",
        "\n",
        "class RecommendDishes(HealthScoreCalculator):\n",
        "\n",
        "  def __init__(self,model,modelArch):\n",
        "    self.flavanoidDB=None\n",
        "    self.model=model\n",
        "    self.modelArch=modelArch\n",
        "    self.loadedTrainedModel=None\n",
        "    self.predictions=None\n",
        "    self.score=None\n",
        "    self.foodIdToNameMapping=None\n",
        "    self.loadIdMapping()\n",
        "    self.loadFlavanoidDB()\n",
        "    self.foodId=list(self.flavanoidDB.keys())\n",
        "    self.flavanoids=list(self.flavanoidDB.values())\n",
        "    self.loadModel(self.model,self.modelArch)\n",
        "    self.encodedFlavanoid=[]\n",
        "    self.userVocab=0\n",
        "    self.userMaxLen=0\n",
        "    HealthScoreCalculator.__init__(self)\n",
        "\n",
        "\n",
        "  def encodeFlavonoid(self):    \n",
        "    encoded=[]\n",
        "    for ele in self.flavanoids:\n",
        "      joinedStr=\" \".join(ele)\n",
        "      encoded.append([one_hot(joinedStr,1405)])\n",
        "    padded=pad_sequences(encoded,maxlen=1405,padding=\"post\")\n",
        "    self.encodedFlavanoid.append(padded)\n",
        " \n",
        "  def loadIdMapping(self):\n",
        "    self.foodIdToNameMapping=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/id_name_mapping.csv\",names=[\"id\",\"dish\"])\n",
        "\n",
        "  def loadFlavanoidDB(self):  \n",
        "    print(\"......Loading flavanoids data.......\")\n",
        "    rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "    self.flavanoidDB={}\n",
        "    for i in range(rawFlavanoids.shape[0]):\n",
        "      self.flavanoidDB[str(rawFlavanoids[\"id\"][i])]=rawFlavanoids[\"flavanoids\"][i].split(\"|\")\n",
        "    print(\"total flanavnoids={}\".format(len(self.flavanoidDB)))\n",
        "    \n",
        "  def loadModel(self,model,modelArch):\n",
        "    self.model=model\n",
        "    self.modelArch=modelArch\n",
        "    print(\".....Loading Trained Model.........\")\n",
        "    #rawData=pd.read_csv('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/unembedded_grouped_cleaned_data.csv')\n",
        "    #rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "    print(\".....Loading Architecture= {}\".format(modelArch))\n",
        "    jsonFile=open('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/'+modelArch,'r')\n",
        "    loadedModelJson=jsonFile.read()\n",
        "    jsonFile.close()\n",
        "    self.loadedTrainedModel=model_from_json(loadedModelJson)\n",
        "    print(\"using {} model for recommendation\".format(model.split(\".h5\")[0]))\n",
        "    print(\".....Loading saved weights\")\n",
        "\n",
        "    self.loadedTrainedModel.load_weights(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/\"+model)\n",
        "    \n",
        "    print(\"Trained model loaded successfully\")\n",
        "  \n",
        "  def cleanDoc(self,doc):#doc=list of string\n",
        "    print(\"Cleaning data\")\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in doc]\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tokens = [word for word in tokens if len(word) > 1]\n",
        "    print(\"Cleaned Input Data={}\".format(tokens))\n",
        "    return tokens\n",
        "\n",
        "  def prepareDataToPredict(self,userReview):#userReviews=string\n",
        "    print(\"Vectorizing data\")\n",
        "    userReview=self.cleanDoc(userReview.split(\" \"))    \n",
        "    #since rating has to be predicted for all the dishes\n",
        "    #userReviewVector=self.userReviewVectorizer.transform([userReview]*len(self.flavanoids))\n",
        "    d=\" \".join(userReview)\n",
        "    userReviewVector=[one_hot(d,userVocab)]*len(self.foodId)\n",
        "    userReviewVector=pad_sequences(userReviewVector,maxlen=userMaxLen,padding=\"post\")\n",
        "    self.encodeFlavonoid()\n",
        "    return self.foodId,[np.array(userReviewVector),self.encodedFlavanoid]\n",
        "\n",
        "  def calculateRating(self,healthScores):\n",
        "    self.prediction=[]\n",
        "    for i in range(len(self.foodId)):\n",
        "      val=((self.predictions[i][0]/10)+healthScores[i])/1.5*10\n",
        "      self.prediction.append(round(val if val<5 else get(48000,50000)/10000,4))\n",
        "    # self.prediction=np.clip(self.prediction,None,get(4800,5000)/1000)\n",
        "  def recommend(self,userReview):\n",
        "    print(\".....Processing Input Data......\")\n",
        "    foodId,testInputs = self.prepareDataToPredict(userReview)  \n",
        "    self.predictions =self.loadedTrainedModel.predict(testInputs)\n",
        "    idToName=dict(zip(self.foodIdToNameMapping.id.tolist(),self.foodIdToNameMapping.dish.tolist()))\n",
        "    # for i in range(len(self.foodId)):\n",
        "    #   print(\"{}={}\".format(idToName[int(foodId[i])],self.predictions[i][0]))\n",
        "    return foodId,self.predictions\n",
        "\n",
        "  def displayTable(self,fieldNames,data):\n",
        "    table=PrettyTable()\n",
        "    table.field_names=fieldNames\n",
        "    for ele in data:\n",
        "      table.add_row(ele)\n",
        "    print(table)\n",
        "  \n",
        "  def predictRatingForGivenDish(self,userReview,foodId,userVocab,userMaxLen):#foodId Strig\n",
        "    \n",
        "    d=self.cleanDoc(userReview.split(\" \"))\n",
        "    print(d)\n",
        "    userReviewVector=encodeToOneHot(d,userTokenMap)\n",
        "    print(userReviewVector)\n",
        "    userReviewVector=userReviewVector+[0]*(userMaxLen-len(userReviewVector))\n",
        "    #print(userReviewVector)\n",
        "\n",
        "    ele=self.flavanoidDB[foodId]\n",
        "    foodReviewVector=encodeToOneHot(d,foodTokenMap)\n",
        "    foodReviewVector=foodReviewVector+[0]*(1405-len(foodReviewVector))\n",
        "    # foodReviewVector=pad_sequences(foodReviewVector,maxlen=1405,padding=\"post\")\n",
        "    \n",
        "    self.predictions =self.loadedTrainedModel.predict([[userReviewVector],[foodReviewVector]])\n",
        "    # for i in range(len(self.foodId)):\n",
        "    #   print(\"{}={}\".format(idToName[int(foodId[i])],self.predictions[i][0]))\n",
        "    return self.predictions\n",
        "\n",
        "  def recommendDishWithHealthScore(self,dishId,height,weight,age,gender,condition,bmratio,steps,floors):\n",
        "    self.scores=self.calculateScore(height,weight,age,gender,condition,bmratio,steps,floors)\n",
        "    healthScores=list(self.scores.values())\n",
        "    idToName=dict(zip(self.foodIdToNameMapping.id.tolist(),self.foodIdToNameMapping.dish.tolist()))\n",
        "    data=[]\n",
        "    \n",
        "    data.append([idToName[int(dishId)],self.predictions[0],self.scores[i]])\n",
        "     \n",
        "    self.displayTable([\"dish\",\"rating\",\"healthScore\"],data)\n",
        "    #return foodId,self.predictions,self.score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x=RecommendDishes(\"EmbeddedRs.h5\",\"EmbeddedRsModelArchi.json\")\n",
        "#y=x.recommendDishWithHealthScore(\"really good food\",5.6,60,25,'m','normal',3000,10,22.1)\n",
        "review=eval(rawData[\"userReviews\"][0])\n",
        "review=\" \".join(review)\n",
        "print(review)\n",
        "print(x.predictRatingForGivenDish(review,\"2\",8613,186))\n",
        "x.recommendDishWithHealthScore(\"2\",5.6,60,25,'m','normal',3000,10,22.1)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "......Loading flavanoids data.......\n",
            "total flanavnoids=1380\n",
            ".....Loading Trained Model.........\n",
            ".....Loading Architecture= EmbeddedRsModelArchi.json\n",
            "using EmbeddedRs model for recommendation\n",
            ".....Loading saved weights\n",
            "Trained model loaded successfully\n",
            "delicious and easy to make\n",
            "Cleaning data\n",
            "Cleaned Input Data=['delicious', 'easy', 'make']\n",
            "['delicious', 'easy', 'make']\n",
            "[1988, 2345, 4385]\n",
            "[[4.8031583]]\n",
            "+------------+-------------+---------------------+\n",
            "|    dish    |    rating   |     healthScore     |\n",
            "+------------+-------------+---------------------+\n",
            "| keema aloo | [4.8031583] | 0.19683263476757054 |\n",
            "+------------+-------------+---------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}