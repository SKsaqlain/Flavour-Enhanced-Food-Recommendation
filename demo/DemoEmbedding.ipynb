{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQOe75Tt57f6",
        "colab_type": "text"
      },
      "source": [
        "Recommendation System implemented Using DeepCoNN architecture with input being user food reviews, food flavanoids data and using tf-idf for embedding.    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro69eqw47Klz",
        "colab_type": "code",
        "outputId": "5593c843-c5d5-4dfe-c54f-bf567a6bf133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip install geocoder\n",
        "!pip install pyowm\n",
        "!pip install prettytable\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import linalg\n",
        "from time import time\n",
        "import os\n",
        "import pickle\n",
        "from prettytable import PrettyTable\n",
        "from random import randrange as get\n",
        "\n",
        "import geocoder\n",
        "import json\n",
        "import requests\n",
        "import pyowm\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import string \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model,model_from_json\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "from keras.layers import Input, Dense , Embedding\n",
        "from keras.layers.merge import Add, Dot, Concatenate\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: geocoder in /usr/local/lib/python3.6/dist-packages (1.38.1)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.6/dist-packages (from geocoder) (0.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from geocoder) (2.21.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from geocoder) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from geocoder) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from geocoder) (7.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ratelim->geocoder) (4.4.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (3.0.4)\n",
            "Requirement already satisfied: pyowm in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: geojson<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pyowm) (2.5.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from pyowm) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (2.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJtwmaD7Nnm",
        "colab_type": "code",
        "outputId": "35a49ef3-4e4b-407f-ee37-946fe7976fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp2OkZ4b7z5G",
        "colab_type": "code",
        "outputId": "8399c386-646c-453f-9418-363b7e1ac11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "rawData=pd.read_csv('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/unembedded_grouped_cleaned_data.csv')\n",
        "# print(\"before sampleing \",rawData.shape)\n",
        "# print(rawData.head())\n",
        "# data5=rawData[rawData[\"rating\"]==5]\n",
        "# data4=rawData[rawData[\"rating\"]==4]\n",
        "# data3=rawData[rawData[\"rating\"]==3]\n",
        "# data2=rawData[rawData[\"rating\"]==2]\n",
        "# data1=rawData[rawData[\"rating\"]==1]\n",
        "# #after sampling\n",
        "# rawData=pd.concat([data1,data2,data3.sample(1380),data4.sample(1380),data5.sample(1380)])\n",
        "# print(\"after sampling \",rawData.shape)\n",
        "print(rawData.head())\n",
        "print(rawData.shape)\n",
        "#rawData=rawData[list(map(lambda x:len(x)>1,rawData[\"userReviews\"]))]\n",
        "print(rawData.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  ...                                 foodReviews\n",
            "0           0  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "1           1  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "2           2  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "3           3  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "4           8  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "(58283, 6)\n",
            "(58283, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oip07vDu707D",
        "colab_type": "code",
        "outputId": "1f652e28-4bbb-46dd-ca97-67fa64de285b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "# rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/database.csv\",names=[\"id\",\"flavanoids\"])\n",
        "# print(rawFlavanoids.shape)\n",
        "rawFlavanoids.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>flavanoids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id                                         flavanoids\n",
              "0           0   1  Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...\n",
              "1           1   2  AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...\n",
              "2           2   3  3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...\n",
              "3           3   4  AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...\n",
              "4           4   5  3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfsNrhhm8SzO",
        "colab_type": "code",
        "outputId": "19c049d2-1b8b-43f6-8d7a-348081972a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "flavanoidDB={}\n",
        "for i in range(rawFlavanoids.shape[0]):\n",
        "  flavanoidDB[str(rawFlavanoids[\"id\"][i])]=str([ele.strip().replace(\" \",\"-\") for ele in rawFlavanoids[\"flavanoids\"][i].split(\"|\")])\n",
        "print(\"total dishes={}\".format(len(flavanoidDB)))\n",
        "print(list(flavanoidDB.keys())[:5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total dishes=1380\n",
            "['1', '2', '3', '4', '5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLUkY_TMdsRh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ca5e7768-c387-460f-e450-fcdf475e7fb9"
      },
      "source": [
        "print(flavanoidDB[\"1\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ethyl-Lactate', '3,4-Dihydroxybenzaldehyde', 'DL-Liquiritigenin', '2-Acetylpyrrole', 'benzaldehyde', 'Ethyl-Vinyl-Ketone', '5-Hydroxymethylfurfural', '2,3,5-Trimethylpyrazine', 'Octan-2-ol', '2-Butanone', 'coumarin', 'indole', 'CHEBI:49249', 'Isobutyl-isothiocyanate', '2-Isobutyl-3-Methoxypyrazine', 'Allyl-methyl-sulfide', 'Humulene', 'AC1L9CNW', 'Vitamin-U', 'Alpha-Terpinyl-Acetate', 'S-Propyl-thioacetate', 'Terpinen-4-ol', 'Isobornyl-acetate', 'Phlorizin', 'Methyl-tetradecanoate', '(Z)-Hex-3-en-1-ol', '.alpha.-Calacorene', 'Tetrasulfide,-dimethyl', 'M-Cymene', '(-)-Epicatechin-gallate', 'Methyleugenol', '2-Nonanol', 'cinnamaldehyde', '2-Hexanone', 'Valencene', '2-Methylbutyraldehyde', '3,5-Diethyl-1,2,4-trithiolane', 'Isobutyl-Acetate', 'Coumestrol', 'Ocimene', 'farnesol', 'Citral', '2-isopropyl-6-methoxypyrazine', 'hydrogen-cyanide', 'Ethyl-Propyl-Disulfide', 'Methyl-propyl-disulfide', '2-Mercapto-2-Methyl-1-Pentanol', 'Hexanal', 'Damascenone', '2,3-butanedione', '1,3-Dithiane', '3,4-Dimethylphenol', 'Heptanal', 'Propyl-sulfide', 'trans,trans-2,4-Nonadienal', 'trans-2-Nonenal', 'Ethyl-Acetate', 'gamma-Caprolactone', 'D-Lactic-acid', 'Tetradecanoic-acid', '3-Octanone', 'Isobutyl-Formate', 'hydrogen-sulfide', 'Isovaleric-Acid', 'cis-Jasmone', 'D-mannitol', '156420-69-8', 'Cianidanol', 'Methyl-Benzoate', 'Eucalyptol', 'Pentanal', 'Propenyl-propyl-disulfide', 'Methyl-Stearate', 'Allyl-Mercaptan', 'Curcumenol', 'Linalool', 'alpha-Cadinene', 'Menthone', 'palmitic-acid', 'Diallyl-trisulfide', 'Pyridine', '1-Dodecanol', 'Ethyl-Benzoate', 'Hexyl-acetate', 'Nerolidyl-acetate', 'indole-3-acetic-acid', '2-Acetyl-2-thiazoline', '2,6-Dimethylpyrazine', '3-Methylcyclopentane-1,2-dione', 'Nonanal', 'Tributyrin', 'Pyruvic-acid', 'Terpinolene', 'UNII-M41Y60O5BZ', '4-Methyl-5-Thiazoleethanol', 'Isoquercitrin', '2-Phenylethanol', 'Linalyl-Acetate', 'Diisopropyl-trisulfide', 'Gamma-Terpinene', 'Diallyl-Disulfide', '3-Phenylpropanoic-acid', 'Beta-Phellandrene', 'phloretin', 'Carvacrol', 'Curcumene', 'dimethyl-sulfide', 'Ethyl-Formate', '2,6-Dimethoxyphenol', 'carnosol', 'Disulfide,-methyl-1-propenyl', '1-octanol', '2-Isopropyl-5-methylcyclohexanone', 'Beta-Caryophyllene', 'Neral', '1-Propanethiol', 'Phytol', '1-Octen-3-Ol', 'daidzein', 'Methyl-octanoate', 'nan', 'cis-Isoeugenol', 'Alpha-Ionone', 'Dipropyl-trisulfide', 'Daidzin', 'Beta-Pinene', 'Allyl-Methyl-Disulfide', 'Isopentyl-formate', '2-Acetyl-5-Methylfuran', '2-Methyl-2-Pentenal', '(Z)-cinnamyl-alcohol', '2-Heptanone', 'sulfur-dioxide', 'Dipentene', 'Methyl-Acetate', '2-Methyl-1-propanol', 'methanethiol', 'Sinapic-Acid', 'Isoamyl-Acetate', 'quercetin', 'L-Rhamnose', 'isopropanol', '2-Pentanol', '2-Methyl-1-Butanol', '3-Carene', '2-Isopropyl-3-Methoxypyrazine', 'Vanillic-acid', 'Furfuryl-acetate', '2,3-Pentanedione', '.alpha.-Cubebene', '2-Heptanol', '(-)-Zingiberene', 'butein', '24168-70-5', '2-Nonanone', 'calcium-lactate', '3-Hexanone', '(-)-gamma-cadinene', 'hydrogen-peroxide', '(5xi,7xi,10xi)-eudesma-4(14),11-diene', 'S-allyl-L-cysteine', 'Methyl-propyl-trisulfide', 'gamma-Decalactone', '(-)-Epigallocatechin', 'gamma-Butyrolactone', 'methyl-(9E,12Z)-octadeca-9,12-dienoate', '4-Methyl-5-Vinylthiazole', '3-methylthiopropanol', '2-(4-Hydroxyphenyl)ethanol', 'Tangeretin', 'gamma-Nonanolactone', 'Cyclopentanone', 'Carvone', '(Z)-Ethyl-cinnamate', 'methyl-salicylate', '6-Methyl-5-Hepten-2-One', 'Tiglic-aldehyde', '2,3-Dimethylbenzofuran', 'D-Isoleucine-Methyl-Ester-Hydrochloride', 'D-Camphor', 'betaine', 'P-Cymene', '4-Methyl-2-pentanone', '(+)-alpha-Terpineol', '2-Methyltetrahydrofuran-3-One', '3-Pentanone', 'Cinnamic-Acid', '4-isopropylbenzaldehyde', 'Styrene', 'phenol', '2-Ethyl-4-hydroxy-5-methyl-3(2H)-furanone', 'Methyl-jasmonate', '(Z)-Hex-4-enal', 'resveratrol', '(+)-Camphene', 'Cubenol', '3-Ethyl-2,5-dimethylpyrazine', '1-Popc', 'acetic-acid', '2-Phenylethyl-formate', 'trans-Anethole', '2-Undecanol', 'succinic-acid', 'alpha-Cadinol', 'Dl-Methionine', 'salicylic-acid', 'Isobutyraldehyde', '3-Thujene', 'CID-644104', '1,3-Diphenyl-1-butanone', 'Gallocatechin', 'dibutyl-phthalate', 'Geraniol', 'Acrolein', '5-Methylfurfural', 'D-Limonene', 'Isopentyl-benzoate', 'Thiamine-Hydrochloride', '2,5-Dimethylthiophene', '(+)-Neomenthol', 'l-.alpha.-Cadinol', '2-Methylbutyl-Acetate', 'Isoborneol', '1-(4-Methylphenyl)ethanol', '3-Mercapto-2-methylpentanal', '3-Methyl-2-Cyclopenten-1-One', 'Benzyl-Salicylate', '(+)-delta-Cadinene', 'Octanal', 'Acetal', '3-Methylbutanal', 'Ethyl-Cinnamate', 'Beta-Ionone', 'Acetyleugenol', 'cis-Cinnamic-acid', '3-Methyl-2-butenal', '3-Methoxybenzaldehyde', 'octanoic-acid', 'benzyl-isothiocyanate', 'Ethyl-Octanoate', '2-Pentyl-Acetate', '33368-82-0', 'Isopropyl-Acetate', 'eugenol', 'guaiacol', '2-amino-3-(prop-2-en-1-ylsulfanyl)propanoic-acid', 'UNII-H5E892YJGG', 'Phenylacetic-Acid', '2-Pentanone', 'Undecanoic-Acid', 'Pyrrolidine', 'Allyl-propyl-sulfide', 'benzoic-acid', 'DL-Tartaric-acid', 'Benzyl-tiglate', 'Linamarin', '3,4-Dihydroxybenzoic-Acid', '2-Methoxy-4-vinylphenol', '3242-08-8', 'Acetophenone', '4-Hexen-1-Ol', '2-Methylbenzaldehyde', 'Nerolidol', '2-Furylacetone', 'Farnesal', 'Butyl-propyl-disulfide', '2-Acetylthiazole', 'Maltol', 'naringenin', '1-Pyrroline', '2,5-Dimethylpyrazine', 'Alpha-Terpinene', 'Dimethyl-disulfide', 'propionic-acid', '.beta.-Bourbonene', 'trans-2-Hexen-1-Ol', 'Dipropyl-disulfide', '2,6-Di-tert-butyl-4-methylphenol', 'NSC5112', '1-Methylnaphthalene', 'Hexanoic-Acid', 'Alpha-Pinene', 'Phenethyl-acetate', '2-Methylpyrazine', 'Aromadendrene', '6753-98-6', '(E)-gamma-Bisabolene', 'Ethyl-Levulinate', 'trans-3-Hexen-1-ol', 'Borneol', 'Beta-Selinene', '1-Nonanol', 'Beta-Elemene', 'Taxifolin', 'Myrcene', '1-Hexanol', 'Caryophyllene', 'Juniper-camphor', 'Allyldimethylsilane', '4-Vinylphenol', 'Octan-2-one', '1-Phenylethyl-acetate', 'Furfuryl-Alcohol', 'Ethyl-caproate', 'lauric-acid', 'kaempferol', 'Camphene', '4-Hexen-3-One', 'Thymol', 'Isoeugenol', 'isoliquiritigenin', '2,3,5,6-Tetramethylpyrazine', 'Allyl-Alcohol', '3-Hexanol', 'ethanol', 'alpha-Muurolene', '227456-27-1', '2-Methylpentanal', 'caftaric-acid', '3-Methyl-2-Butanol', '(-)-Epicatechin', 'Allyl-Isothiocyanate', 'Thymol-methyl-ether', 'cis-3-Hexenal', 'acetone', '(-)-Limonene', '3-Methyl-2-Buten-1-Ol', 'Beta-Terpineol', 'p-coumaric-acid', 'Clove-Oil', '4-hydroxybenzaldehyde', 'S-Methyl-thioacetate', 'alpha-TERPINEOL', 'D-Fenchone', 'Estragole', '3-Heptanone', '7-methyl-4-methylidene-1-propan-2-yl-2,3,4a,5,6,8a-hexahydro-1H-naphthalene', '2-Furaldehyde', 'gingerol', 'Dl-Phenylalanine', 'Methyl-propenyl-ketone', '(-)-Epigallocatechin-gallate', 'Acetovanillone', '(E)-Hept-2-enal', 'apigenin', 'vanillin', '3-Methyl-2-Cyclohexen-1-One', 'Diallyl-Sulfide', 'Dimethyl-trisulfide', 'Alpha-Phellandrene', 'luteolin', '1-propanol', 'phenylacetaldehyde', '(+)-alpha-phellandrene', 'Propyl-butyrate', 'Benzyl-Acetate', '3-Methyl-1-butanol', '1-Phenylethanol', 'Benzyl-Benzoate', 'Isobutyl-butyrate', '2-Acetylpyridine', '4-isopropylbenzyl-alcohol', 'Isorhamnetin', '1-Penten-3-Ol', '2-Pentylfuran', 'L-histidine', 'Propyl-acetate', 'Chavicol', 'AC1NST8Q', 'Syringaldehyde', 'Nonanoic-Acid', '2-Undecanone', 'nicotine', '.beta.-Sesquiphellandrene', 'Sabinene-hydrate', 'Methyl-Palmitate', 'Neryl-propionate', 'cinnamyl-alcohol', 'Piperitol', 'cis-3-Hexenyl-acetate', 'Geranyl-Acetate', 'Allyl-Propyl-Disulfide', '(+)-gamma-cadinene', 'naphthalene', '2-Methylbutanoic-acid', 'benzyl-alcohol', 'alpha-Maltose', 'alpha-L-Sorbopyranose', 'Ethyl-Butyrate', 'Heptanoic-Acid', 'thiamine', 'Allyl-Methyl-Trisulfide', '2-Tridecanone', 'L-phenylalanine', 'Propionaldehyde', '3-(Methylthio)propionaldehyde', 'Caryophyllene-oxide', 'Diallyl-tetrasulfide', 'dimethyl-sulfoxide', 'Propyl-Benzoate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2P8aGBy-P_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processedData=rawData.copy()\n",
        "for ele in flavanoidDB.keys():\n",
        "  try:\n",
        "    processedData.loc[processedData[\"food_id\"]==ele,\"foodReviews\"]=flavanoidDB[ele]\n",
        "  except:\n",
        "    print(\"food id {} not found in the dataset\".format(ele))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXb5pfK7GWx6",
        "colab_type": "code",
        "outputId": "368448fe-3952-4130-b765-3c80dd9b5431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "processedData.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9974</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10340</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['feeling', 'healthy', 'great', 'replication',...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12047</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['yum', 'will', 'make', 'again']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13451</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['turned', 'out', 'great', 'i', 'added', 'pean...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>18226</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['fantastic', 'tasting', 'completely', 'simple...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        foodReviews\n",
              "0           0  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "1           1  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "2           2  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "3           3  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "4           8  ...  ['4-Hexen-3-One', 'Mesityl-Oxide', '3-Phenylpr...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0LKJy5oN_Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "userReviews=processedData[\"userReviews\"].tolist()\n",
        "foodReviews=processedData[\"foodReviews\"].tolist()\n",
        "def cleanDoc(doc):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in doc]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "  return tokens\n",
        "def cnvStrToList(data):\n",
        "  for i in  range(len(data)):\n",
        "    if(data[i][-1]==\"]\"):\n",
        "      data[i]=eval(data[i])\n",
        "    else:\n",
        "      data[i]=eval(data[i]+\"]\")\n",
        "  return data\n",
        "\n",
        "def getVocab(data):\n",
        "  l=[]\n",
        "  maxLen=0\n",
        "  for row in data:\n",
        "    l.extend(row)\n",
        "  l=set(l)\n",
        "  return len(l)\n",
        "\n",
        "userReviews=[cleanDoc(ele) for ele in cnvStrToList(userReviews)]\n",
        "foodReviews=[ele for ele in cnvStrToList(foodReviews)]\n",
        "\n",
        "userMaxLen=len(max(userReviews,key=lambda x:len(x)))\n",
        "userVocab=getVocab(userReviews)\n",
        "foodMaxLen=1405\n",
        "foodVocab=1405\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BreRANibP_OB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f900e08c-7787-4ed0-8869-5e85fcf31856"
      },
      "source": [
        "print(userMaxLen)\n",
        "print(userVocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186\n",
            "8613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz3yvYhhQcqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "userReviews=[\" \".join(ele) for ele in userReviews]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKuryUu4RBxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3551b5d7-5ffe-4b75-874b-f15c88b68085"
      },
      "source": [
        "modFoodReviews=[]\n",
        "for ele in foodReviews:\n",
        "  modFoodReviews.append(\" \".join(flv.replace(\" \",\"-\") for flv in ele))\n",
        "print(modFoodReviews[0])\n",
        "foodReviews=modFoodReviews"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4-Hexen-3-One Mesityl-Oxide 3-Phenylpropanoic-acid succinic-acid 1-Heptanol Isoeugenol 3,4-Dihydroxybenzaldehyde salicylic-acid Isobutyl-mercaptan phloretin 23726-92-3 Isobutyraldehyde isoliquiritigenin Allyl-Alcohol DL-Liquiritigenin 2-Acetylpyrrole dimethyl-sulfide benzaldehyde Ethyl-Vinyl-Ketone Ethyl-3-hydroxyhexanoate Ethyl-dodecanoate CID-644104 2,3,5-Trimethylpyrazine DL-Valine Gallocatechin 2-Butanone 1-octanol 2-Isopropyl-5-methylcyclohexanone Tetradecanal 2-Methylpentanal taurine Geraniol Acrolein trans-2-Hexenal Ethyl-Nonanoate coumarin indole L-lysine Thiamine-Hydrochloride Neral 3-Methylindole 2'-Hydroxyacetophenone (+)-Neomenthol (-)-Epicatechin Allyl-Isothiocyanate daidzein (-)-beta-Pinene Alpha-Ionone cis-3-Hexenal Daidzin Beta-Pinene butyraldehyde acetone (Z)-cinnamyl-alcohol 3-Methyl-2-Buten-1-Ol 2-Heptanone Terpinyl-propionate Vitamin-U p-coumaric-acid delta-Undecalactone (+)-delta-Cadinene L-Lactic-acid Octanal 3-Methylbutanal 4-hydroxybenzaldehyde Undecanal alpha-TERPINEOL Phlorizin Beta-Ionone 2-Methyl-1-propanol methanethiol Acetylpyrazine P-Cresol Perillaldehyde (-)-Epicatechin-gallate delta-Tetradecalactone Sinapic-Acid Delta-Dodecalactone cinnamaldehyde Isoamyl-Acetate L-aspartic-acid quercetin Valencene 2-Methylbutyraldehyde (-)-alpha-Pinene 2-Furaldehyde 3-Methyl-2-butenal isopropanol 2-Undecanol octanoic-acid Methyl-Hexanoate (-)-Epigallocatechin-gallate 6-methyl-2-(oxiran-2-yl)hept-5-en-2-ol Isoquinoline 2-Methyl-1-Butanol trans-2-Dodecenal farnesol Citral Vanillic-acid vanillin apigenin Furfuryl-acetate Dimethyl-trisulfide Alpha-Phellandrene luteolin phenylacetaldehyde 2,3-Pentanedione hydrogen-cyanide Propyl-butyrate 1-Furfurylpyrrole Hexanal 2,3-butanedione Methyl-butyrate Phenylacetic-Acid 3-Methyl-1-butanol 2-Pentanone Pyrazine Benzyl-Benzoate Heptanal 2-Nonanone lactic-acid calcium-lactate Ethyl-Acetate gamma-Caprolactone D-Lactic-acid Pyrrolidine Tetradecanoic-acid 3-Hexanone Isorhamnetin hydrogen-sulfide hydrogen-peroxide Isovaleric-Acid L-histidine Linamarin 3,4-Dihydroxybenzoic-Acid D-mannitol gamma-Decalactone gamma-Dodecalactone (-)-Epigallocatechin Cianidanol 1-Decanol Methyl-Benzoate Syringaldehyde Nonyl-Acetate Eucalyptol 5,6-dimethyloxan-2-one Pentanal 3-methylthiopropanol 5-Methylquinoxaline 2-(4-Hydroxyphenyl)ethanol Nonanoic-Acid 2-Undecanone nicotine 2-Ethylbutanal Nerolidol (2E,4E)-deca-2,4-dienal gamma-Nonanolactone Cyclopentanone Farnesal cinnamyl-alcohol Piperitenone 2-Undecenal 1-Undecanol 50-69-1 Linalool Decanoic-acid cis-3-Hexenyl-acetate 104-50-7 Maltol naringenin 1-Octen-3-One 1-Pyrroline Geranyl-Acetate Ethyl-2-methylbutyrate 6-Methyl-5-Hepten-2-One Tiglic-aldehyde Dimethyl-disulfide Menthone propionic-acid palmitic-acid trans-2-Hexen-1-Ol NSC5112 benzyl-alcohol Ethyl-Heptanoate 1-Methylnaphthalene Methyl-2-furoate betaine alpha-Maltose l-ascorbic-acid P-Cymene Violet-leaf-aldehyde butyric-acid 4-Methyl-2-pentanone 3658-77-3 3-Pentanone Alpha-Pinene Hexanoic-Acid Pyridine alpha-L-Sorbopyranose Phenethyl-acetate 2-Methylpyrazine Cinnamic-Acid 23747-48-0 Heptanoic-Acid Ethyl-Butyrate Delta-Decalactone thiamine Ethyl-Benzoate trans-3-Hexen-1-ol Hexyl-acetate phenol Styrene formic-acid Pyrrole Phenethylamine indole-3-acetic-acid 2-Tridecanone 2-Ethyl-4-hydroxy-5-methyl-3(2H)-furanone 1-Nonanol 3-Methylcyclopentane-1,2-dione Propionaldehyde Tributyrin 3-(Methylthio)propionaldehyde Methyl-jasmonate Nonanal Decanal nerol Methyl-Linoleate Taxifolin Myrcene Pyruvic-acid Terpinolene 1-Hexanol Ethyl-Decanoate Dodecanal Octan-2-one Bis(methylthio)methane Linalyl-Acetate Isoquercitrin 2-Phenylethanol Furfuryl-Alcohol Prunin lauric-acid Gamma-Terpinene kaempferol dimethyl-sulfoxide\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmmKN9duRb6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_userReviews=[one_hot(d,userVocab) for d in userReviews]\n",
        "encoded_foodReviews=[one_hot(d,foodVocab) for d in foodReviews]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyFrRhDfRvyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "931754c7-1bfb-4e76-f587-acc0d081b0dd"
      },
      "source": [
        "print(encoded_userReviews[0])\n",
        "print(encoded_foodReviews[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[838, 3225, 6678]\n",
            "[634, 633, 1004, 36, 987, 329, 1004, 37, 1053, 551, 1053, 1369, 1252, 352, 1004, 634, 2, 459, 1053, 708, 1143, 721, 1125, 1380, 1004, 1153, 1185, 819, 508, 32, 11, 597, 618, 1140, 33, 285, 44, 571, 1263, 44, 1004, 293, 44, 223, 620, 742, 597, 1004, 1342, 465, 32, 381, 535, 597, 491, 1369, 27, 597, 1066, 1342, 997, 1074, 597, 211, 201, 347, 690, 330, 597, 1044, 44, 1395, 855, 1076, 811, 640, 1078, 539, 613, 1004, 270, 587, 1002, 235, 391, 819, 1094, 1370, 496, 738, 845, 1224, 849, 1004, 1044, 443, 496, 738, 1368, 116, 1385, 484, 508, 1004, 908, 597, 522, 1369, 880, 597, 119, 894, 1135, 1062, 316, 880, 1084, 1053, 447, 531, 447, 372, 811, 851, 1053, 168, 1004, 342, 634, 1347, 129, 845, 1075, 385, 496, 1224, 597, 908, 1369, 681, 237, 1175, 880, 1270, 1108, 391, 1026, 447, 828, 240, 1053, 447, 484, 398, 1192, 630, 811, 1372, 1053, 524, 1346, 597, 33, 845, 738, 597, 1158, 1004, 908, 597, 1225, 753, 597, 996, 91, 1053, 908, 223, 492, 1026, 1006, 908, 597, 1296, 597, 790, 492, 1342, 969, 597, 880, 882, 597, 908, 1369, 1392, 330, 597, 201, 1047, 552, 181, 1053, 108, 334, 1236, 630, 1140, 1173, 845, 89, 577, 689, 597, 1004, 609, 163, 52, 17, 768, 1369, 740, 313, 597, 1004, 1155, 908, 768, 1035, 1053, 1004, 908, 1369, 1392, 597, 1107, 502, 653, 962, 97, 597, 1005, 851, 1053, 1302, 1348, 44, 630, 964, 715, 703, 851, 1053, 393, 270, 1053, 1004, 20, 1154, 163, 33, 163, 211, 1388, 1053, 811, 786, 1301, 1004, 634, 1086, 1053, 703, 258, 964, 780, 964, 484, 492, 1337, 1369, 239, 908, 962, 154, 1048, 630, 863, 1342, 1006, 505, 597, 36, 776, 1004, 6, 1342, 184, 597, 634, 1258, 208, 728, 1053, 597, 476, 617, 597, 675, 982, 697, 974, 1254, 597, 634, 543, 964, 65, 1189, 1114, 484, 508, 1249, 597, 1333, 1369, 996, 268, 591, 1369, 265, 532, 1053, 849, 1004, 824, 630, 592, 268, 825, 394, 260, 1369, 1223, 1004, 36, 1369, 372, 213, 630, 44, 597, 553, 1006, 908, 1342, 293, 597, 36, 711, 835, 1140, 427, 735, 1212, 1053, 1077, 1053, 330, 597, 633, 1369, 880, 1312, 653, 508, 44, 902, 1369, 820, 908, 597, 940, 1286, 845, 851, 811, 925, 1053, 880, 876, 293, 1313, 835, 210, 1053, 634, 908, 597, 1107, 461, 1359, 1004, 1004, 1107, 845, 738, 138, 1053, 1086, 845, 811, 749, 82, 630, 597, 575, 1071, 1053, 463, 1242, 992, 389, 1053, 44, 768, 447, 780, 1078, 44, 962, 330, 1004, 633, 1369, 880, 1295, 630, 591, 205, 307, 1053, 1282, 545, 1076, 1004, 578, 1053, 597, 1311, 597, 44, 634, 578, 1342, 908, 1004, 1353, 239, 1369, 103, 1004, 831, 1369, 597, 1056, 323, 368, 1004, 659, 323, 908, 735, 238, 229, 173, 908, 1320, 253, 298, 952, 1053, 817, 1369, 914, 44, 932, 276, 1346, 597, 36, 485, 659, 637, 1246, 630, 882, 597, 1049, 1236, 508, 680, 1323, 1053, 964, 470, 256, 1140, 61]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9HFvXblR0yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_userReviews=pad_sequences(encoded_userReviews,maxlen=userMaxLen,padding=\"post\")\n",
        "padded_foodReviews=pad_sequences(encoded_foodReviews,maxlen=foodMaxLen,padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU8i60vUSK_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "c1792c77-683f-4816-e486-f5962d049032"
      },
      "source": [
        "print(type(padded_userReviews[0]))\n",
        "print(padded_userReviews[0])\n",
        "print(padded_foodReviews[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[ 838 3225 6678    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "[ 634  633 1004 ...    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDAkAMP_SRKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processedData[\"userReviews\"]=[str(ele) for ele in padded_userReviews.tolist()]\n",
        "processedData[\"foodReviews\"]=[str(ele) for ele in padded_foodReviews.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DRP1H-SIPAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train/test split for our model is unique, we need to hold out a\n",
        "# set of users and movies so that our network never learns those \n",
        "testSize = 0.005\n",
        "\n",
        "# get testSize percentage of users\n",
        "uniqueUsers = processedData.loc[:, \"user_id\"].unique()\n",
        "usersSize = len(uniqueUsers)\n",
        "test_idx = np.random.choice(usersSize,\n",
        "                              size=int(usersSize * testSize),\n",
        "                              replace=False)\n",
        "\n",
        "# get test users\n",
        "testUsers = uniqueUsers[test_idx]\n",
        "\n",
        "# everyone else is a training user\n",
        "trainUsers = np.delete(uniqueUsers, test_idx)\n",
        "\n",
        "test = processedData[processedData[\"user_id\"].isin(testUsers)]\n",
        "train = processedData[processedData[\"user_id\"].isin(trainUsers)]\n",
        "\n",
        "uniqueTestFood = test[\"food_id\"].unique()\n",
        "\n",
        "# drop the movies that also appear in our test set. In order to be\n",
        "# a true train/test split, we are forced to discard some data entirely\n",
        "train = train.where(np.logical_not(train[\"food_id\"].isin(uniqueTestFood))).dropna()\n",
        "train=shuffle(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2gb9Q4BYpms",
        "colab_type": "code",
        "outputId": "ff17559b-00cf-4552-d1ca-64b5cdc62b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14649</th>\n",
              "      <td>27341.0</td>\n",
              "      <td>3164.0</td>\n",
              "      <td>399</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[3779, 1373, 258, 7084, 1595, 6410, 3731, 4836...</td>\n",
              "      <td>[44, 1348, 631, 1004, 634, 2, 597, 817, 597, 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49698</th>\n",
              "      <td>91262.0</td>\n",
              "      <td>13787.0</td>\n",
              "      <td>241</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[838, 4479, 6678, 3365, 2351, 1073, 8054, 5972...</td>\n",
              "      <td>[1004, 634, 2, 27, 394, 32, 11, 597, 618, 285,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50180</th>\n",
              "      <td>91866.0</td>\n",
              "      <td>6832.0</td>\n",
              "      <td>254</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[885, 3225, 885, 5278, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[891, 849, 383, 1369, 1392, 855, 1076, 140, 13...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10066</th>\n",
              "      <td>18290.0</td>\n",
              "      <td>12136.0</td>\n",
              "      <td>350</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[5449, 3225, 1373, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[44, 1348, 631, 1004, 634, 2, 708, 1143, 1355,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7309</th>\n",
              "      <td>13965.0</td>\n",
              "      <td>14851.0</td>\n",
              "      <td>523</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[1473, 7950, 5278, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[11, 597, 618, 285, 44, 571, 1263, 1342, 53, 6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                        foodReviews\n",
              "14649     27341.0  ...  [44, 1348, 631, 1004, 634, 2, 597, 817, 597, 6...\n",
              "49698     91262.0  ...  [1004, 634, 2, 27, 394, 32, 11, 597, 618, 285,...\n",
              "50180     91866.0  ...  [891, 849, 383, 1369, 1392, 855, 1076, 140, 13...\n",
              "10066     18290.0  ...  [44, 1348, 631, 1004, 634, 2, 708, 1143, 1355,...\n",
              "7309      13965.0  ...  [11, 597, 618, 285, 44, 571, 1263, 1342, 53, 6...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ANBx5tnIvtR",
        "colab_type": "code",
        "outputId": "1463c73c-2f65-407d-df19-ed1110bae5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"train={} test={}\".format(train.shape,test.shape))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train=(19647, 6) test=(218, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGmlk4ZgTkkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b60d964-758e-4f54-8017-1ea9c85fdf37"
      },
      "source": [
        "print(type(train[\"userReviews\"][0]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3BRQ0uTI4rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainUserReviews=[eval(ele) for ele in train[\"userReviews\"].tolist()]\n",
        "testUserReviews=[eval(ele) for ele in test[\"userReviews\"].tolist()]\n",
        "\n",
        "trainFoodReviews=[eval(ele) for ele in train[\"foodReviews\"].tolist()]\n",
        "testFoodReviews=[eval(ele) for ele in test[\"foodReviews\"].tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKt0GMiJLaAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"Embedding Dimensions => userReviews={} || foodReviews={}\".format(trainUserReviews.shape,trainFoodReviews.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3TjSeG5MAzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "class DeepCoNN():\n",
        "    def __init__(self,\n",
        "                 userEmbeddingSize,\n",
        "                 foodEmbeddingSize,\n",
        "                 userMaxLength,\n",
        "                 foodMaxLength,\n",
        "                 hiddenSize,\n",
        "                 filters=100,\n",
        "                 kernelSize=3,\n",
        "                 strides=1):\n",
        "        self.userEmbeddingSize = userEmbeddingSize\n",
        "        self.foodEmbeddingSize=foodEmbeddingSize\n",
        "        self.hiddenSize = hiddenSize\n",
        "        self.filters = filters\n",
        "        self.kernelSize = kernelSize\n",
        "        self.userMaxLength=userMaxLength\n",
        "        self.foodMaxLength=foodMaxLength\n",
        "        self.inputU, self.towerU = self.createDeepCoNnTower(self.userEmbeddingSize,self.userMaxLength)\n",
        "        self.inputF, self.towerF = self.createDeepCoNnTower(self.foodEmbeddingSize,self.foodMaxLength)\n",
        "        self.joined = Concatenate()([self.towerU, self.towerF])\n",
        "        self.outNeuron = Dense(1)(self.joined)\n",
        "\n",
        "    def createDeepCoNnTower(self,embeddingSize,maxLength):\n",
        "        inputLayer = Input(shape=(maxLength,))\n",
        "        embeddingLayer=Embedding(embeddingSize,300,input_length=maxLength)(inputLayer)\n",
        "        tower = Conv1D(filters=self.filters,\n",
        "                       kernel_size=self.kernelSize,\n",
        "                       kernel_initializer='random_uniform',activation=\"tanh\")(embeddingLayer)\n",
        "        # tower=LeakyReLU(alpha=0.05)(tower)\n",
        "        tower = MaxPooling1D()(tower)\n",
        "        tower = Flatten()(tower)\n",
        "        tower = Dense(self.hiddenSize,activation=\"tanh\",kernel_initializer='random_uniform')(tower)\n",
        "        # tower=LeakyReLU(alpha=0.05)(tower)\n",
        "        return inputLayer, tower\n",
        "\n",
        "    def createDeepCoNnDp(self):\n",
        "        # dotproduct = Dot(axes=1)([self.towerU, self.towerF])\n",
        "        # output = Add()([self.outNeuron, dotproduct])\n",
        "        output=self.outNeuron\n",
        "        self.model = Model(inputs=[self.inputU, self.inputF], outputs=[output])\n",
        "        opt=optimizers.Adadelta()\n",
        "        self.model.compile(optimizer=opt, loss='mse')\n",
        "        \n",
        "    def train(self, trainData,trainUserReviews,trainFoodReviews, batch_size, epochs=1):\n",
        "        tensorboard = TensorBoard(log_dir=\"tf_logs/{}\".format(pd.Timestamp(int(time()), unit=\"s\")))\n",
        "        self.createDeepCoNnDp()\n",
        "        print(self.model.summary())\n",
        "        \n",
        "        # userReviews = np.array(trainData.loc[:, \"userReviews\"])\n",
        "        # foodReviews = np.array(trainData.loc[:, \"foodReviews\"])\n",
        "        userReviews=trainUserReviews\n",
        "        foodReviews=trainFoodReviews\n",
        "\n",
        "        self.train_inputs = [userReviews, foodReviews]\n",
        "        self.train_outputs = trainData.loc[:, \"rating\"]\n",
        "        \n",
        "        self.history = self.model.fit(self.train_inputs,\n",
        "                                      self.train_outputs,\n",
        "                                      callbacks=[tensorboard],\n",
        "                                      validation_split=0.05,\n",
        "                                      batch_size=batch_size,\n",
        "                                      epochs=epochs)\n",
        "        self.model_json=self.model.to_json()\n",
        "        with open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/SimpleRsModelArchi.json\",\"w\") as json_file:\n",
        "          json_file.write(self.model_json)\n",
        "          print(\"model architecture saved\")\n",
        "          self.model.save_weights(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/SimpleRs.h5\")\n",
        "          print(\"saved model to disk\")\n",
        "          \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCEiaBGRqN3",
        "colab_type": "code",
        "outputId": "7c7a4a59-48d0-4096-f61f-d0eb4f2ae33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hiddenSize = 50\n",
        "\n",
        "deepconn = DeepCoNN(userEmbeddingSize=userVocab,foodEmbeddingSize=foodVocab,hiddenSize=hiddenSize,userMaxLength=userMaxLen,foodMaxLength=foodMaxLen)\n",
        "\n",
        "batch_size = 100\n",
        "deepconn.train(train,trainUserReviews,trainFoodReviews, batch_size, epochs=1)\n",
        "\n",
        "deepconn.model.save(\"cnn.h5\")\n",
        "# print(train_embedded.loc[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 186)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1405)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 186, 300)     2583900     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1405, 300)    421500      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 184, 100)     90100       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 1403, 100)    90100       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 92, 100)      0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 701, 100)     0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9200)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 70100)        0           max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 50)           460050      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 50)           3505050     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 100)          0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            101         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 7,150,801\n",
            "Trainable params: 7,150,801\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 18664 samples, validate on 983 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/1\n",
            "18664/18664 [==============================] - 450s 24ms/step - loss: 1.1854 - val_loss: 0.6122\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "model architecture saved\n",
            "saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rotX_tNNSKra",
        "colab_type": "code",
        "outputId": "70e32e66-d0f7-4235-822f-803a9aa9dd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "testInputs = [testUserReviews, testFoodReviews]\n",
        "#print(testInputs)\n",
        "# dat = pd.DataFrame(testInputs)\n",
        "# dat.to_csv(\"/content/gdrive/My Drive/DeepConn/Deep_Learning_Recommender_System//test_data.csv\")\n",
        "\n",
        "trueRating = np.array(list(test.loc[:, \"rating\"])).reshape((-1, 1))\n",
        "\n",
        "predictions = deepconn.model.predict(testInputs)\n",
        "print(predictions)\n",
        "error = np.square(predictions - trueRating)\n",
        "\n",
        "print(\"MSE:\", np.average(error))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.5732775]\n",
            " [4.213745 ]\n",
            " [4.9860196]\n",
            " [4.9806867]\n",
            " [4.2043767]\n",
            " [4.142575 ]\n",
            " [4.6063595]\n",
            " [3.9633756]\n",
            " [4.6612067]\n",
            " [4.4908586]\n",
            " [4.9370646]\n",
            " [4.5457897]\n",
            " [4.6629853]\n",
            " [4.666633 ]\n",
            " [4.652584 ]\n",
            " [4.2079935]\n",
            " [4.5185704]\n",
            " [3.9696007]\n",
            " [4.667431 ]\n",
            " [4.4970818]\n",
            " [4.212031 ]\n",
            " [3.9578304]\n",
            " [4.6556606]\n",
            " [4.4853125]\n",
            " [4.194404 ]\n",
            " [4.3029537]\n",
            " [4.330371 ]\n",
            " [4.906009 ]\n",
            " [4.8338284]\n",
            " [4.0795465]\n",
            " [4.880176 ]\n",
            " [4.6025596]\n",
            " [4.214484 ]\n",
            " [4.6551104]\n",
            " [4.8586025]\n",
            " [4.4541693]\n",
            " [4.544135 ]\n",
            " [4.5013223]\n",
            " [4.7024126]\n",
            " [4.225022 ]\n",
            " [4.705155 ]\n",
            " [4.8872466]\n",
            " [4.1956406]\n",
            " [4.30419  ]\n",
            " [4.3316073]\n",
            " [5.0293865]\n",
            " [4.2287927]\n",
            " [3.9518461]\n",
            " [4.649677 ]\n",
            " [4.479328 ]\n",
            " [4.5043864]\n",
            " [4.6551743]\n",
            " [4.931799 ]\n",
            " [4.518867 ]\n",
            " [4.9472485]\n",
            " [4.4067383]\n",
            " [4.5060263]\n",
            " [4.6164255]\n",
            " [4.6858644]\n",
            " [4.2611184]\n",
            " [4.2024   ]\n",
            " [4.0238633]\n",
            " [4.7611756]\n",
            " [4.8418994]\n",
            " [4.5292716]\n",
            " [4.7207623]\n",
            " [4.325788 ]\n",
            " [4.640319 ]\n",
            " [4.7789416]\n",
            " [4.767763 ]\n",
            " [3.95873  ]\n",
            " [4.656562 ]\n",
            " [4.486213 ]\n",
            " [4.4016213]\n",
            " [4.645657 ]\n",
            " [4.762127 ]\n",
            " [4.5022244]\n",
            " [4.5230227]\n",
            " [4.5048122]\n",
            " [4.7291393]\n",
            " [4.8534365]\n",
            " [4.7768555]\n",
            " [3.951146 ]\n",
            " [4.6489773]\n",
            " [4.478629 ]\n",
            " [4.831485 ]\n",
            " [4.40854  ]\n",
            " [4.6525755]\n",
            " [4.770311 ]\n",
            " [4.8086233]\n",
            " [4.0867753]\n",
            " [4.6912665]\n",
            " [4.2788982]\n",
            " [4.702585 ]\n",
            " [4.8975544]\n",
            " [4.5538816]\n",
            " [4.511457 ]\n",
            " [4.571768 ]\n",
            " [4.5309896]\n",
            " [4.211677 ]\n",
            " [4.212149 ]\n",
            " [3.9668036]\n",
            " [4.6646338]\n",
            " [4.494286 ]\n",
            " [4.64527  ]\n",
            " [4.215206 ]\n",
            " [4.71563  ]\n",
            " [4.5127835]\n",
            " [4.5127835]\n",
            " [4.7530727]\n",
            " [4.514475 ]\n",
            " [3.9754908]\n",
            " [4.6733217]\n",
            " [4.5029736]\n",
            " [4.4340653]\n",
            " [3.9534373]\n",
            " [4.6512685]\n",
            " [4.4809203]\n",
            " [4.6271706]\n",
            " [5.021204 ]\n",
            " [4.416792 ]\n",
            " [4.6608276]\n",
            " [3.9040415]\n",
            " [4.6018724]\n",
            " [4.4315243]\n",
            " [4.8737826]\n",
            " [3.9733074]\n",
            " [4.671139 ]\n",
            " [4.75418  ]\n",
            " [4.458783 ]\n",
            " [4.722568 ]\n",
            " [3.9713287]\n",
            " [4.6691594]\n",
            " [4.4988117]\n",
            " [4.580726 ]\n",
            " [4.574918 ]\n",
            " [4.632485 ]\n",
            " [4.50897  ]\n",
            " [4.7342954]\n",
            " [3.9735894]\n",
            " [4.67142  ]\n",
            " [4.5010715]\n",
            " [4.9202824]\n",
            " [4.708404 ]\n",
            " [4.562218 ]\n",
            " [4.7120814]\n",
            " [4.6384406]\n",
            " [4.5160046]\n",
            " [4.5160046]\n",
            " [4.8249106]\n",
            " [4.6836734]\n",
            " [4.478927 ]\n",
            " [4.0711904]\n",
            " [3.9290507]\n",
            " [4.6268816]\n",
            " [4.4565334]\n",
            " [4.945616 ]\n",
            " [4.3876677]\n",
            " [4.821277 ]\n",
            " [4.5225415]\n",
            " [4.6033187]\n",
            " [4.4118094]\n",
            " [4.655845 ]\n",
            " [4.325741 ]\n",
            " [4.525495 ]\n",
            " [3.9745762]\n",
            " [4.6724067]\n",
            " [4.5020585]\n",
            " [3.9475439]\n",
            " [4.6453743]\n",
            " [4.475026 ]\n",
            " [4.803288 ]\n",
            " [5.059596 ]\n",
            " [4.5353403]\n",
            " [4.529532 ]\n",
            " [4.5870996]\n",
            " [4.778713 ]\n",
            " [4.660716 ]\n",
            " [3.9704   ]\n",
            " [4.668231 ]\n",
            " [4.497883 ]\n",
            " [4.4525905]\n",
            " [4.418423 ]\n",
            " [4.7394   ]\n",
            " [4.5065885]\n",
            " [4.9089103]\n",
            " [4.7104597]\n",
            " [5.2032876]\n",
            " [4.5346804]\n",
            " [4.949544 ]\n",
            " [4.487294 ]\n",
            " [4.977603 ]\n",
            " [4.443045 ]\n",
            " [4.1917067]\n",
            " [4.781871 ]\n",
            " [4.5417595]\n",
            " [4.2106724]\n",
            " [4.5673566]\n",
            " [4.511701 ]\n",
            " [4.75396  ]\n",
            " [4.2123675]\n",
            " [3.9752657]\n",
            " [4.673096 ]\n",
            " [4.502748 ]\n",
            " [4.0266786]\n",
            " [4.028617 ]\n",
            " [4.4790945]\n",
            " [4.5729628]\n",
            " [5.097218 ]\n",
            " [4.038464 ]\n",
            " [4.522647 ]\n",
            " [4.82038  ]\n",
            " [4.5198636]\n",
            " [4.7060113]\n",
            " [3.966827 ]\n",
            " [4.664658 ]\n",
            " [4.4943094]\n",
            " [4.608163 ]]\n",
            "MSE: 0.49793801129469445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEA0LPy4j3Tg",
        "colab_type": "code",
        "outputId": "66e98d15-42bb-4b26-b062-452c3becb0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "\n",
        "\n",
        "#the funtion is needed when loading the vectorizer\n",
        "def dummy_fun(doc):\n",
        "  return doc\n",
        "\n",
        "\n",
        "class HealthScoreCalculator():\n",
        "  def __init__(self):\n",
        "    self.weights = {\n",
        "\t'normal' : {'calories' : 1, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1}, \n",
        "\t'diabetes' : {'calories' : 1, 'protein' : 1, 'sugar' : 4.25, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 3, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1},\n",
        "\t'bp' : {'calories' : 1, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 9, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1},\n",
        "\t'obesity' : {'calories' : 7, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1}\n",
        "\t}\n",
        "    self.predictedScores=None\n",
        "\n",
        "  def convToComStand(self,value):\n",
        "    if value.endswith('mg'):\n",
        "      value = value[:value.index('mg')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value) / 1000\n",
        "    elif value.endswith('g'):\n",
        "      value = value[:value.index('g')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value)\n",
        "    elif value.endswith('kcal'):\n",
        "      value = value[:value.index('kcal')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value)\n",
        "\n",
        "    elif value.endswith('IU'):\n",
        "      value = value[:value.index('IU')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = (float(value) / 3.3) / 1000000\n",
        "    \n",
        "    return value\n",
        "\n",
        "  def elixir(self,allowed, weights, bmratio, type = 'normal'):\n",
        "    weights = weights[type]\n",
        "    database = json.load(open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/database.json\", 'rb'))\n",
        "    x = {}\n",
        "    for dish in database:\n",
        "      dishId = dish['dish_id']\n",
        "      nutrients = dish['nutrients']\n",
        "      if all(nutrients.values()):\n",
        "        for nutrient in nutrients:\n",
        "          value = nutrients[nutrient]\n",
        "          if value:\n",
        "            #converting to  common standard\n",
        "            value = self.convToComStand(value[0])\n",
        "            nutrients[nutrient] = value\n",
        "        #################################\n",
        "        recbn = ['protein', 'dietary_fiber']\n",
        "        recbase = 0\n",
        "        for i in recbn:\n",
        "          recbase += weights[i] * nutrients[i] / allowed[i]\n",
        "\n",
        "        part1 = 0\n",
        "        part2 = 0\n",
        "        if nutrients['carbs']:\n",
        "          part1 = weights['dietary_fiber'] * nutrients['dietary_fiber'] / nutrients['carbs']\n",
        "          part2 =  0.1 * (nutrients['carbs'] - nutrients['dietary_fiber'] - nutrients['sugar']) / nutrients['carbs']\n",
        "\n",
        "        recbase = recbase + part1 + part2\n",
        "        #################################\n",
        "        restbn = ['carbs', 'cholesterol', 'sodium', 'sat_fat', 'fat', 'sugar']\n",
        "        restbase = 0\n",
        "        for i in restbn:\n",
        "          restbase += weights[i] * nutrients[i] / allowed[i]\n",
        "\n",
        "        part1 = 0\n",
        "        part2 = 0\n",
        "        if nutrients['sugar'] and nutrients['carbs']:\n",
        "          part1 = weights['carbs'] * nutrients['sugar'] / nutrients['carbs']\n",
        "\n",
        "        if nutrients['sat_fat'] and nutrients['fat']:\n",
        "          part2 = weights['sat_fat'] * nutrients['sat_fat'] / nutrients['fat']\n",
        "        \n",
        "        restbase = part1 + part2\t\t\t\n",
        "        #################################\n",
        "        recan = ['vitamin_a', 'vitamin_c', 'calcium', 'iron']\n",
        "        recadd = 0\n",
        "        for i in recan:\n",
        "          recadd += weights[i] * nutrients[i] / allowed[i]\n",
        "        #################################\n",
        "\n",
        "        mult = bmratio\n",
        "        div = ((1 + mult) * restbase)\n",
        "        if div:\n",
        "          score = recbase + (mult * recadd) / div\n",
        "        else:\n",
        "          score = 0\n",
        "\n",
        "        x[dishId] = score\n",
        "    self.predictedScores=x\n",
        "    return x\n",
        "\n",
        "  def get_lat_long(self,ip_addr =\"me\"):\n",
        "    g = geocoder.ip(ip_addr)\n",
        "    return g.latlng\n",
        "\n",
        "  def get_temp(self,lat, lon):\n",
        "    owm = pyowm.OWM('9bb248641cc71b7ab1b7040317ec6ac9')\n",
        "    observation_list = owm.weather_around_coords(lat, lon)\n",
        "    tot_temp = 0\n",
        "    if observation_list != None:\n",
        "      for i in observation_list:\n",
        "        w = i.get_weather()\n",
        "        temp = w.get_temperature('fahrenheit')['temp']\n",
        "        tot_temp += temp\n",
        "\n",
        "      temp = tot_temp / len(observation_list)\n",
        "\n",
        "      return temp\n",
        "\n",
        "  def elevation(self,lat, lng):\n",
        "    loc = str(lat) + ',' + str(lng)\n",
        "    apikey = \"AIzaSyAd0cewCPnbRF_0082PULMybInWNhWgDjA\"\n",
        "    base_url = \"https://maps.googleapis.com/maps/api/elevation/json\"\n",
        "    params = dict()\n",
        "    params[\"locations\"] = str(loc)\n",
        "    params[\"key\"] = apikey\n",
        "    r = requests.get(base_url, params=params)\n",
        "    results = json.loads(r.text).get('results')\n",
        "    return 847\n",
        "    return results[0]['elevation']\n",
        "\n",
        "  def adaptive_daily_value(self,weight, height, gender, age, steps, height_travelled, bmratio):\n",
        "    latlong = self.get_lat_long()\n",
        "    temp = self.get_temp(*latlong)\n",
        "    altitude =self.elevation(*latlong)\n",
        "\n",
        "    allowed = {'calories' : 2079.35, 'protein' : 50, 'fat' : 70, 'sat_fat' : 24, 'carbs' : 310, 'sugar' : 30, 'dietary_fiber' : 30, 'sodium' : 2.3, 'cholesterol' : 300, 'vitamin_a' : 0.0008, 'vitamin_c' : 0.08, 'iron' : 0.0087, 'calcium' : 1}\n",
        "    \n",
        "    work = 9.8 * weight * height_travelled * 0.000239006 + weight * steps / 6000\n",
        "    \n",
        "    bmr = weight * 10 + 6.25 * height - 5 * age\n",
        "    if gender == 'm':\n",
        "      bmr += 5\n",
        "    else:\n",
        "      bmr -= 161\n",
        "\n",
        "    daily_cal = round(bmratio * bmr + work, 2)\n",
        "    if temp != None:\n",
        "      daily_cal = daily_cal * (1 + (85 - temp) / 800)\n",
        "\n",
        "      for i in allowed:\n",
        "        allowed[i] = allowed[i] * daily_cal / 2079.35\n",
        "\n",
        "    na_multi = 1 + 0.015 * (((temp - 32) * 0.56) - 23)\n",
        "    allowed['sodium'] = na_multi * allowed['sodium'] + (altitude / 1000) ** 2.5\n",
        "\n",
        "    return allowed\n",
        "  def calculateScore(self,height,weight,age,gender,condition,bmratio,steps, floors):\n",
        "    floors = floors * 10 * 3.28084\n",
        "    allowed = self.adaptive_daily_value(weight, height, gender, age, steps, floors, bmratio)\n",
        "    score = self.elixir(allowed, self.weights, bmratio, type = condition)\n",
        "    return score\n",
        "\n",
        "class RecommendDishes(HealthScoreCalculator):\n",
        "\n",
        "  def __init__(self,model,modelArch):\n",
        "    self.flavanoidDB=None\n",
        "    self.model=model\n",
        "    self.modelArch=modelArch\n",
        "    self.loadedTrainedModel=None\n",
        "    self.predictions=None\n",
        "    self.score=None\n",
        "    self.foodIdToNameMapping=None\n",
        "    self.loadIdMapping()\n",
        "    self.loadFlavanoidDB()\n",
        "    self.foodId=list(self.flavanoidDB.keys())\n",
        "    self.flavanoids=list(self.flavanoidDB.values())\n",
        "    self.loadModel(self.model,self.modelArch)\n",
        "    self.encodedFlavanoid=[]\n",
        "    self.userVocab=0\n",
        "    self.userMaxLen=0\n",
        "    HealthScoreCalculator.__init__(self)\n",
        "\n",
        "\n",
        "  def encodeFlavonoid(self):    \n",
        "    encoded=[]\n",
        "    for ele in self.flavanoids:\n",
        "      joinedStr=\" \".join(ele)\n",
        "      encoded.append([one_hot(joinedStr,1405)])\n",
        "    padded=pad_sequences(encoded,maxlen=1405,padding=\"post\")\n",
        "    self.encodedFlavanoid.append(padded)\n",
        " \n",
        "  def loadIdMapping(self):\n",
        "    self.foodIdToNameMapping=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/id_name_mapping.csv\",names=[\"id\",\"dish\"])\n",
        "\n",
        "  def loadFlavanoidDB(self):  \n",
        "    print(\"......Loading flavanoids data.......\")\n",
        "    rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "    self.flavanoidDB={}\n",
        "    for i in range(rawFlavanoids.shape[0]):\n",
        "      self.flavanoidDB[str(rawFlavanoids[\"id\"][i])]=rawFlavanoids[\"flavanoids\"][i].split(\"|\")\n",
        "    print(\"total flanavnoids={}\".format(len(self.flavanoidDB)))\n",
        "    \n",
        "  def loadModel(self,model,modelArch):\n",
        "    self.model=model\n",
        "    self.modelArch=modelArch\n",
        "    print(\".....Loading Trained Model.........\")\n",
        "    #rawData=pd.read_csv('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/unembedded_grouped_cleaned_data.csv')\n",
        "    #rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "    print(\".....Loading Architecture= {}\".format(modelArch))\n",
        "    jsonFile=open('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/'+modelArch,'r')\n",
        "    loadedModelJson=jsonFile.read()\n",
        "    jsonFile.close()\n",
        "    self.loadedTrainedModel=model_from_json(loadedModelJson)\n",
        "    print(\"using {} model for recommendation\".format(model.split(\".h5\")[0]))\n",
        "    print(\".....Loading saved weights\")\n",
        "\n",
        "    self.loadedTrainedModel.load_weights(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/\"+model)\n",
        "    \n",
        "    print(\"Trained model loaded successfully\")\n",
        "  \n",
        "  def cleanDoc(self,doc):#doc=list of string\n",
        "    print(\"Cleaning data\")\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in doc]\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tokens = [word for word in tokens if len(word) > 1]\n",
        "    print(\"Cleaned Input Data={}\".format(tokens))\n",
        "    return tokens\n",
        "\n",
        "  def prepareDataToPredict(self,userReview):#userReviews=string\n",
        "    print(\"Vectorizing data\")\n",
        "    userReview=self.cleanDoc(userReview.split(\" \"))    \n",
        "    #since rating has to be predicted for all the dishes\n",
        "    #userReviewVector=self.userReviewVectorizer.transform([userReview]*len(self.flavanoids))\n",
        "    d=\" \".join(userReview)\n",
        "    userReviewVector=[one_hot(d,userVocab)]*len(self.foodId)\n",
        "    userReviewVector=pad_sequences(userReviewVector,maxlen=userMaxLen,padding=\"post\")\n",
        "    self.encodeFlavonoid()\n",
        "    return self.foodId,[np.array(userReviewVector),self.encodedFlavanoid]\n",
        "\n",
        "  def calculateRating(self,healthScores):\n",
        "    self.prediction=[]\n",
        "    for i in range(len(self.foodId)):\n",
        "      val=((self.predictions[i][0]/10)+healthScores[i])/1.5*10\n",
        "      self.prediction.append(round(val if val<5 else get(48000,50000)/10000,4))\n",
        "    # self.prediction=np.clip(self.prediction,None,get(4800,5000)/1000)\n",
        "  def recommend(self,userReview):\n",
        "    print(\".....Processing Input Data......\")\n",
        "    foodId,testInputs = self.prepareDataToPredict(userReview)  \n",
        "    self.predictions =self.loadedTrainedModel.predict(testInputs)\n",
        "    idToName=dict(zip(self.foodIdToNameMapping.id.tolist(),self.foodIdToNameMapping.dish.tolist()))\n",
        "    # for i in range(len(self.foodId)):\n",
        "    #   print(\"{}={}\".format(idToName[int(foodId[i])],self.predictions[i][0]))\n",
        "    return foodId,self.predictions\n",
        "\n",
        "  def displayTable(self,fieldNames,data):\n",
        "    table=PrettyTable()\n",
        "    table.field_names=fieldNames\n",
        "    for ele in data:\n",
        "      table.add_row(ele)\n",
        "    print(table)\n",
        "  \n",
        "  def predictRatingForGivenDish(self,userReview,foodId,userVocab,userMaxLen):#foodId Strig\n",
        "    \n",
        "    d=\" \".join(self.cleanDoc(userReview))\n",
        "    userReviewVector=[one_hot(d,self.userVocab)]\n",
        "    userReviewVector=pad_sequences(userReviewVector,maxlen=self.userMaxLen,padding=\"post\")\n",
        "\n",
        "    ele=self.flavanoidDB[foodId]\n",
        "    d=\" \".join(ele)\n",
        "    foodReviewVector=([one_hot(d,1405)])\n",
        "    foodReviewVector=pad_sequences(foodReviewVector,maxlen=1405,padding=\"post\")\n",
        "    \n",
        "    self.predictions =self.loadedTrainedModel.predict([userReviewVector,foodReviewVector])\n",
        "    # for i in range(len(self.foodId)):\n",
        "    #   print(\"{}={}\".format(idToName[int(foodId[i])],self.predictions[i][0]))\n",
        "    return self.predictions\n",
        "\n",
        "  def recommendDishWithHealthScore(self,userReview,height,weight,age,gender,condition,bmratio,steps,floors):\n",
        "    foodId,self.predictions=self.recommend(userReview)\n",
        "    self.scores=self.calculateScore(height,weight,age,gender,condition,bmratio,steps,floors)\n",
        "    healthScores=list(self.scores.values())\n",
        "    idToName=dict(zip(self.foodIdToNameMapping.id.tolist(),self.foodIdToNameMapping.dish.tolist()))\n",
        "    data=[]\n",
        "    self.calculateRating(healthScores)\n",
        "    for i in range(len(self.foodId)):\n",
        "      data.append([idToName[int(foodId[i])],self.predictions[i][0],healthScores[i]])\n",
        "      # data.append([idToName[int(foodId[i])],self.prediction[i],healthScores[i]])\n",
        "    self.displayTable([\"dish\",\"rating\",\"healthScore\"],data)\n",
        "    return foodId,self.predictions,self.score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x=RecommendDishes(\"SimpleRs.h5\",\"SimpleRsModelArchi.json\")\n",
        "#y=x.recommendDishWithHealthScore(\"really good food\",5.6,60,25,'m','normal',3000,10,22.1)\n",
        "print(x.predictRatingForGivenDish(\"i good food\",\"1\",8613,186))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "......Loading flavanoids data.......\n",
            "total flanavnoids=1380\n",
            ".....Loading Trained Model.........\n",
            ".....Loading Architecture= SimpleRsModelArchi.json\n",
            "using SimpleRs model for recommendation\n",
            ".....Loading saved weights\n",
            "Trained model loaded successfully\n",
            "Cleaning data\n",
            "Cleaned Input Data=[]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3617e168781c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRecommendDishes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SimpleRs.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SimpleRsModelArchi.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;31m#y=x.recommendDishWithHealthScore(\"really good food\",5.6,60,25,'m','normal',3000,10,22.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictRatingForGivenDish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i good food\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8613\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m186\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-3617e168781c>\u001b[0m in \u001b[0;36mpredictRatingForGivenDish\u001b[0;34m(self, userReview, foodId, userVocab, userMaxLen)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mfoodReviewVector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoodReviewVector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1405\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadedTrainedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserReviewVector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfoodReviewVector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;31m# for i in range(len(self.foodId)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;31m#   print(\"{}={}\".format(idToName[int(foodId[i])],self.predictions[i][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have shape (186,) but got array with shape (0,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-KPeNhSj0zV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = ['delicious', 'and', 'easy', 'to', 'make']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixLt_H7wJVv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "eb07e201-de82-49f9-ba44-dec6c0b1071d"
      },
      "source": [
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])\n",
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[43], [45], [43], [10], [30]]\n",
            "[[43  0  0  0]\n",
            " [45  0  0  0]\n",
            " [43  0  0  0]\n",
            " [10  0  0  0]\n",
            " [30  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPpYOIg0JYOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}