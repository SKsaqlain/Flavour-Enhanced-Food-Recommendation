{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoDeepCoNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQOe75Tt57f6",
        "colab_type": "text"
      },
      "source": [
        "Recommendation System implemented Using DeepCoNN architecture with input being user food reviews, food flavanoids data and using tf-idf for embedding.    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro69eqw47Klz",
        "colab_type": "code",
        "outputId": "552e0301-fd6a-44e0-df30-eacf95eb6c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip install geocoder\n",
        "!pip install pyowm\n",
        "!pip install prettytable\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import linalg\n",
        "from time import time\n",
        "import os\n",
        "import pickle\n",
        "from prettytable import PrettyTable\n",
        "from random import randrange as get\n",
        "\n",
        "import geocoder\n",
        "import json\n",
        "import requests\n",
        "import pyowm\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import string \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model,model_from_json\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "from keras.layers import Input, Dense , Embedding\n",
        "from keras.layers.merge import Add, Dot, Concatenate\n",
        "from keras import optimizers\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 90kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting geocoder\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/6b/13166c909ad2f2d76b929a4227c952630ebaf0d729f6317eb09cbceccbab/geocoder-1.38.1-py2.py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from geocoder) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from geocoder) (2.21.0)\n",
            "Collecting ratelim\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/98/7e6d147fd16a10a5f821db6e25f192265d6ecca3d82957a4fdd592cad49c/ratelim-0.1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from geocoder) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from geocoder) (7.1.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2020.4.5.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ratelim->geocoder) (4.4.2)\n",
            "Installing collected packages: ratelim, geocoder\n",
            "Successfully installed geocoder-1.38.1 ratelim-0.1.6\n",
            "Collecting pyowm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/2a/83e26bc87763d0d34767ddc5c875608d4a0a0da66e59730a15c55aec6eff/pyowm-2.10.0-py3-none-any.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 2.5MB/s \n",
            "\u001b[?25hCollecting geojson<3,>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from pyowm) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->pyowm) (2020.4.5.1)\n",
            "Installing collected packages: geojson, pyowm\n",
            "Successfully installed geojson-2.5.0 pyowm-2.10.0\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJtwmaD7Nnm",
        "colab_type": "code",
        "outputId": "13b5caa1-c67b-4673-f399-b626bd3696e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp2OkZ4b7z5G",
        "colab_type": "code",
        "outputId": "b835f743-23cd-4e00-dbee-215eb98ae2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "rawData=pd.read_csv('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/unembedded_grouped_cleaned_data.csv')\n",
        "# print(\"before sampleing \",rawData.shape)\n",
        "# print(rawData.head())\n",
        "# data5=rawData[rawData[\"rating\"]==5]\n",
        "# data4=rawData[rawData[\"rating\"]==4]\n",
        "# data3=rawData[rawData[\"rating\"]==3]\n",
        "# data2=rawData[rawData[\"rating\"]==2]\n",
        "# data1=rawData[rawData[\"rating\"]==1]\n",
        "# #after sampling\n",
        "# rawData=pd.concat([data1,data2,data3.sample(1380),data4.sample(1380),data5.sample(1380)])\n",
        "# print(\"after sampling \",rawData.shape)\n",
        "print(rawData.head())\n",
        "print(rawData.shape)\n",
        "#rawData=rawData[list(map(lambda x:len(x)>1,rawData[\"userReviews\"]))]\n",
        "print(rawData.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  ...                                 foodReviews\n",
            "0           0  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "1           1  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "2           2  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "3           3  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "4           8  ...  ['delicious', 'and', 'easy', 'to', 'make']\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "(58283, 6)\n",
            "(58283, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khQ_jCRgZd2m",
        "colab_type": "code",
        "outputId": "05f36796-4698-42bc-af0a-8e6a528cc776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "rawData[rawData[\"rating\"]==5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9974</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10340</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['feeling', 'healthy', 'great', 'replication',...</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12047</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['yum', 'will', 'make', 'again']</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13451</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['turned', 'out', 'great', 'i', 'added', 'pean...</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>18226</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['fantastic', 'tasting', 'completely', 'simple...</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58276</th>\n",
              "      <td>106497</td>\n",
              "      <td>5751</td>\n",
              "      <td>475</td>\n",
              "      <td>5</td>\n",
              "      <td>['this', 'was', 'awesome', 'i', 'added', 'red'...</td>\n",
              "      <td>['delicious', 'added', 'a', 'clove', 'of', 'ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58277</th>\n",
              "      <td>106499</td>\n",
              "      <td>4004</td>\n",
              "      <td>475</td>\n",
              "      <td>5</td>\n",
              "      <td>['i', 'made', 'this', 'and', 'it', 'was', 'fan...</td>\n",
              "      <td>['delicious', 'added', 'a', 'clove', 'of', 'ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58278</th>\n",
              "      <td>106501</td>\n",
              "      <td>3231</td>\n",
              "      <td>475</td>\n",
              "      <td>5</td>\n",
              "      <td>['added', 'chunks', 'of', 'basa', 'fish', 'bef...</td>\n",
              "      <td>['delicious', 'added', 'a', 'clove', 'of', 'ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58279</th>\n",
              "      <td>106503</td>\n",
              "      <td>3668</td>\n",
              "      <td>475</td>\n",
              "      <td>5</td>\n",
              "      <td>['pretty', 'good', 'i', 'substituted', 'the', ...</td>\n",
              "      <td>['delicious', 'added', 'a', 'clove', 'of', 'ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58282</th>\n",
              "      <td>106509</td>\n",
              "      <td>11346</td>\n",
              "      <td>475</td>\n",
              "      <td>5</td>\n",
              "      <td>['turned', 'out', 'great', 'added', 'more', 's...</td>\n",
              "      <td>['delicious', 'added', 'a', 'clove', 'of', 'ga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37247 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                        foodReviews\n",
              "0               0  ...         ['delicious', 'and', 'easy', 'to', 'make']\n",
              "1               1  ...         ['delicious', 'and', 'easy', 'to', 'make']\n",
              "2               2  ...         ['delicious', 'and', 'easy', 'to', 'make']\n",
              "3               3  ...         ['delicious', 'and', 'easy', 'to', 'make']\n",
              "4               8  ...         ['delicious', 'and', 'easy', 'to', 'make']\n",
              "...           ...  ...                                                ...\n",
              "58276      106497  ...  ['delicious', 'added', 'a', 'clove', 'of', 'ga...\n",
              "58277      106499  ...  ['delicious', 'added', 'a', 'clove', 'of', 'ga...\n",
              "58278      106501  ...  ['delicious', 'added', 'a', 'clove', 'of', 'ga...\n",
              "58279      106503  ...  ['delicious', 'added', 'a', 'clove', 'of', 'ga...\n",
              "58282      106509  ...  ['delicious', 'added', 'a', 'clove', 'of', 'ga...\n",
              "\n",
              "[37247 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYwVSoP-AmHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rawData[\"foodReviews\"]=[\"['The','quick','brown','fox','jumped','over','the','lazy','dog']\"]*rawData.shape[0]\n",
        "# rawData.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oip07vDu707D",
        "colab_type": "code",
        "outputId": "4e5b878c-56d3-473f-994f-d08ec481f233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "# rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/database.csv\",names=[\"id\",\"flavanoids\"])\n",
        "# print(rawFlavanoids.shape)\n",
        "rawFlavanoids.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>flavanoids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id                                         flavanoids\n",
              "0           0   1  Ethyl Lactate|3,4-Dihydroxybenzaldehyde|DL-Liq...\n",
              "1           1   2  AC1LDI49|56424-87-4|3,4-Dihydroxybenzaldehyde|...\n",
              "2           2   3  3-Methyl-1-butanol|Thymol|2-Nonanone|Pyrrolidi...\n",
              "3           3   4  AC1LDI49|56424-87-4|2-Hexenyl propanoate|3,4-D...\n",
              "4           4   5  3,4-Dihydroxybenzaldehyde|DL-Liquiritigenin|2-..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfsNrhhm8SzO",
        "colab_type": "code",
        "outputId": "83d36dad-37fc-4d2b-c707-47f7e6210fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "flavanoidDB={}\n",
        "for i in range(rawFlavanoids.shape[0]):\n",
        "  flavanoidDB[str(rawFlavanoids[\"id\"][i])]=str([ele.strip() for ele in rawFlavanoids[\"flavanoids\"][i].split(\"|\")])\n",
        "print(\"total dishes={}\".format(len(flavanoidDB)))\n",
        "print(list(flavanoidDB.keys())[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total dishes=1380\n",
            "['1', '2', '3', '4', '5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2P8aGBy-P_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processedData=rawData.copy()\n",
        "for ele in flavanoidDB.keys():\n",
        "  try:\n",
        "    processedData.loc[processedData[\"food_id\"]==ele,\"foodReviews\"]=flavanoidDB[ele]\n",
        "  except:\n",
        "    print(\"food id {} not found in the dataset\".format(ele))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXb5pfK7GWx6",
        "colab_type": "code",
        "outputId": "18a05d1d-b84e-4cdb-da49-a5f07f8ee384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "processedData.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9974</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['delicious', 'and', 'easy', 'to', 'make']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10340</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['feeling', 'healthy', 'great', 'replication',...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12047</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['yum', 'will', 'make', 'again']</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13451</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['turned', 'out', 'great', 'i', 'added', 'pean...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>18226</td>\n",
              "      <td>998</td>\n",
              "      <td>5</td>\n",
              "      <td>['fantastic', 'tasting', 'completely', 'simple...</td>\n",
              "      <td>['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        foodReviews\n",
              "0           0  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "1           1  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "2           2  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "3           3  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "4           8  ...  ['4-Hexen-3-One', 'Mesityl Oxide', '3-Phenylpr...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DRP1H-SIPAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train/test split for our model is unique, we need to hold out a\n",
        "# set of users and movies so that our network never learns those \n",
        "testSize = 0.005\n",
        "\n",
        "# get testSize percentage of users\n",
        "uniqueUsers = processedData.loc[:, \"user_id\"].unique()\n",
        "usersSize = len(uniqueUsers)\n",
        "test_idx = np.random.choice(usersSize,\n",
        "                              size=int(usersSize * testSize),\n",
        "                              replace=False)\n",
        "\n",
        "# get test users\n",
        "testUsers = uniqueUsers[test_idx]\n",
        "\n",
        "# everyone else is a training user\n",
        "trainUsers = np.delete(uniqueUsers, test_idx)\n",
        "\n",
        "test = processedData[processedData[\"user_id\"].isin(testUsers)]\n",
        "train = processedData[processedData[\"user_id\"].isin(trainUsers)]\n",
        "\n",
        "uniqueTestFood = test[\"food_id\"].unique()\n",
        "\n",
        "# drop the movies that also appear in our test set. In order to be\n",
        "# a true train/test split, we are forced to discard some data entirely\n",
        "train = train.where(np.logical_not(train[\"food_id\"].isin(uniqueTestFood))).dropna()\n",
        "train=shuffle(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2gb9Q4BYpms",
        "colab_type": "code",
        "outputId": "7d0e2ded-4da3-4f3e-c577-f0472ef4a4f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>food_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>userReviews</th>\n",
              "      <th>foodReviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21824</th>\n",
              "      <td>40062.0</td>\n",
              "      <td>19543.0</td>\n",
              "      <td>1365</td>\n",
              "      <td>5.0</td>\n",
              "      <td>['sooooo', 'good', 'so', 'good', 'make', 'i’ll...</td>\n",
              "      <td>['Geranyl isobutyrate', 'AC1LDI49', '3,4-Dihyd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25637</th>\n",
              "      <td>46126.0</td>\n",
              "      <td>17463.0</td>\n",
              "      <td>315</td>\n",
              "      <td>5.0</td>\n",
              "      <td>['it’s', 'the', 'perfect', 'snack', 'very', 't...</td>\n",
              "      <td>['3,4-Dihydroxybenzaldehyde', 'DL-Liquiritigen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51637</th>\n",
              "      <td>94619.0</td>\n",
              "      <td>4557.0</td>\n",
              "      <td>557</td>\n",
              "      <td>5.0</td>\n",
              "      <td>['really', 'good', 'and', 'easy', 'my', 'whole...</td>\n",
              "      <td>['AC1LDI49', '56424-87-4', '3,4-Dihydroxybenza...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38876</th>\n",
              "      <td>71332.0</td>\n",
              "      <td>14200.0</td>\n",
              "      <td>287</td>\n",
              "      <td>5.0</td>\n",
              "      <td>['really', 'delicious', 'and', 'easy', 'to', '...</td>\n",
              "      <td>['Camphene', '4-Hexen-3-One', 'Thymol', 'Mesit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31935</th>\n",
              "      <td>57944.0</td>\n",
              "      <td>7811.0</td>\n",
              "      <td>990</td>\n",
              "      <td>5.0</td>\n",
              "      <td>['amazing', 'i', 'ended', 'up', 'costing', 'th...</td>\n",
              "      <td>['Ethyl Lactate', '3,4-Dihydroxybenzaldehyde',...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                        foodReviews\n",
              "21824     40062.0  ...  ['Geranyl isobutyrate', 'AC1LDI49', '3,4-Dihyd...\n",
              "25637     46126.0  ...  ['3,4-Dihydroxybenzaldehyde', 'DL-Liquiritigen...\n",
              "51637     94619.0  ...  ['AC1LDI49', '56424-87-4', '3,4-Dihydroxybenza...\n",
              "38876     71332.0  ...  ['Camphene', '4-Hexen-3-One', 'Thymol', 'Mesit...\n",
              "31935     57944.0  ...  ['Ethyl Lactate', '3,4-Dihydroxybenzaldehyde',...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ANBx5tnIvtR",
        "colab_type": "code",
        "outputId": "fab8da81-c329-4d75-b643-208b81708808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"train={} test={}\".format(train.shape,test.shape))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train=(16527, 6) test=(383, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3BRQ0uTI4rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def cleanDoc(doc):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in doc]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "  return tokens\n",
        "\n",
        "def cnvStrToList(data):\n",
        "  for i in  range(len(data)):\n",
        "    if(data[i][-1]==\"]\"):\n",
        "      data[i]=eval(data[i])\n",
        "    else:\n",
        "      data[i]=eval(data[i]+\"]\")\n",
        "  return data\n",
        "\n",
        "\n",
        "\n",
        "def dummy_fun(doc):\n",
        "  return doc\n",
        "\n",
        "\n",
        "def normalizeData(X):\n",
        "  linfnorm=linalg.norm(X,axis=1,ord=np.inf)\n",
        "  return X.astype(np.float)/linfnorm[:,None]\n",
        "\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None,smooth_idf=True) \n",
        "# tfidf=TfidfVectorizer(max_features=241)\n",
        "\n",
        "\n",
        "#trainUserReviewsRaw=train[\"userReviews\"].tolist()\n",
        "\n",
        "trainUserReviewsProcessed=[cleanDoc(ele) for ele in cnvStrToList(train[\"userReviews\"].tolist())]\n",
        "testUserReviewsProcessed=[cleanDoc(ele) for ele in cnvStrToList(test[\"userReviews\"].tolist())]\n",
        "tfidf.fit(trainUserReviewsProcessed)\n",
        "\n",
        "\n",
        "\n",
        "tfidf_features=tfidf.transform(trainUserReviewsProcessed)\n",
        "trainUserReviews=tfidf_features\n",
        "testUserReviews=tfidf.transform(testUserReviewsProcessed)\n",
        "# trainUserReviews=preprocessing.normalize(tfidf_features.toarray(),norm=\"l1\")\n",
        "\n",
        "# testUserReviews=preprocessing.normalize(tfidf.transform(testUserReviewsProcessed).toarray(),norm=\"l1\")\n",
        "#saving the embedding\n",
        "pickle.dump(tfidf,open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/userReviewsTf-Idf.pickle\",\"wb\"))\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None,smooth_idf=True) \n",
        "\n",
        "trainFoodReviewsProcessed=cnvStrToList(train[\"foodReviews\"].tolist())\n",
        "testFoodReviewsProcessed=cnvStrToList(test[\"foodReviews\"].tolist())\n",
        "\n",
        "tfidf.fit([eval(ele) for ele in flavanoidDB.values()])\n",
        "trainFoodReviews=tfidf.transform(trainFoodReviewsProcessed)\n",
        "testFoodReviews=tfidf.transform(testFoodReviewsProcessed)\n",
        "# trainFoodReviews=preprocessing.normalize(tfidf.transform(trainFoodReviewsProcessed).toarray(),norm=\"l1\")\n",
        "# testFoodReviews=preprocessing.normalize(tfidf.transform(testFoodReviewesProcessed).toarray(),norm=\"l1\")\n",
        "#saving the embedding\n",
        "pickle.dump(tfidf,open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/flavanoidsTf-Idf.pickle\",\"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKt0GMiJLaAD",
        "colab_type": "code",
        "outputId": "a01c17c8-d7d8-4302-cd47-6454f621d8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "print(\"Embedding Dimensions => userReviews={} || foodReviews={}\".format(trainUserReviews.shape,trainFoodReviews.shape))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding Dimensions => userReviews=(16527, 6534) || foodReviews=(16527, 1405)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3TjSeG5MAzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "class DeepCoNN():\n",
        "    def __init__(self,\n",
        "                 userEmbeddingSize,\n",
        "                 foodEmbeddingSize,\n",
        "                 hiddenSize,\n",
        "                 filters=100,\n",
        "                 kernelSize=3,\n",
        "                 strides=1):\n",
        "        self.userEmbeddingSize = userEmbeddingSize\n",
        "        self.foodEmbeddingSize=foodEmbeddingSize\n",
        "        self.hiddenSize = hiddenSize\n",
        "        self.filters = filters\n",
        "        self.kernelSize = kernelSize\n",
        "        self.inputU, self.towerU = self.createDeepCoNnTower(self.userEmbeddingSize)\n",
        "        self.inputF, self.towerF = self.createDeepCoNnTower(self.foodEmbeddingSize)\n",
        "        self.joined = Concatenate()([self.towerU, self.towerF])\n",
        "        self.outNeuron = Dense(1)(self.joined)\n",
        "\n",
        "    def createDeepCoNnTower(self,embeddingSize):\n",
        "        inputLayer = Input(shape=(embeddingSize,))\n",
        "        embeddingLayer=Embedding(embeddingSize,300)(inputLayer)\n",
        "        tower = Conv1D(filters=self.filters,\n",
        "                       kernel_size=self.kernelSize,\n",
        "                       kernel_initializer='random_uniform',activation=\"tanh\")(embeddingLayer)\n",
        "        # tower=LeakyReLU(alpha=0.05)(tower)\n",
        "        tower = MaxPooling1D()(tower)\n",
        "        tower = Flatten()(tower)\n",
        "        tower = Dense(self.hiddenSize,activation=\"tanh\",kernel_initializer='random_uniform')(tower)\n",
        "        # tower=LeakyReLU(alpha=0.05)(tower)\n",
        "        return inputLayer, tower\n",
        "\n",
        "    def createDeepCoNnDp(self):\n",
        "        # dotproduct = Dot(axes=1)([self.towerU, self.towerF])\n",
        "        # output = Add()([self.outNeuron, dotproduct])\n",
        "        output=self.outNeuron\n",
        "        self.model = Model(inputs=[self.inputU, self.inputF], outputs=[output])\n",
        "        opt=optimizers.Adadelta()\n",
        "        self.model.compile(optimizer=opt, loss='mse')\n",
        "        \n",
        "    def train(self, trainData,trainUserReviews,trainFoodReviews, batch_size, epochs=1):\n",
        "        tensorboard = TensorBoard(log_dir=\"tf_logs/{}\".format(pd.Timestamp(int(time()), unit=\"s\")))\n",
        "        self.createDeepCoNnDp()\n",
        "        print(self.model.summary())\n",
        "        \n",
        "        # userReviews = np.array(trainData.loc[:, \"userReviews\"])\n",
        "        # foodReviews = np.array(trainData.loc[:, \"foodReviews\"])\n",
        "        userReviews=trainUserReviews\n",
        "        foodReviews=trainFoodReviews\n",
        "\n",
        "        self.train_inputs = [userReviews, foodReviews]\n",
        "        self.train_outputs = trainData.loc[:, \"rating\"]\n",
        "        \n",
        "        self.history = self.model.fit(self.train_inputs,\n",
        "                                      self.train_outputs,\n",
        "                                      callbacks=[tensorboard],\n",
        "                                      validation_split=0.05,\n",
        "                                      batch_size=batch_size,\n",
        "                                      epochs=epochs)\n",
        "        self.model_json=self.model.to_json()\n",
        "        with open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/SimpleRsModelArchi.json\",\"w\") as json_file:\n",
        "          json_file.write(self.model_json)\n",
        "          print(\"model architecture saved\")\n",
        "          self.model.save_weights(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/SimpleRs.h5\")\n",
        "          print(\"saved model to disk\")\n",
        "          \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCEiaBGRqN3",
        "colab_type": "code",
        "outputId": "651987e7-d04b-4d2e-d3d2-3b74d61861a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        }
      },
      "source": [
        "hiddenSize = 50\n",
        "\n",
        "deepconn = DeepCoNN(trainUserReviews.shape[1],trainFoodReviews.shape[1], hiddenSize)\n",
        "\n",
        "batch_size = 100\n",
        "deepconn.train(train,trainUserReviews,trainFoodReviews, batch_size, epochs=1)\n",
        "\n",
        "deepconn.model.save(\"cnn.h5\")\n",
        "# print(train_embedded.loc[0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 6534)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1405)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 6534, 300)    1960200     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1405, 300)    421500      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 6532, 100)    90100       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 1403, 100)    90100       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 3266, 100)    0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 701, 100)     0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 326600)       0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 70100)        0           max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 50)           16330050    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 50)           3505050     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 100)          0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            101         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 22,397,101\n",
            "Trainable params: 22,397,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 15700 samples, validate on 827 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/1\n",
            "15700/15700 [==============================] - 1751s 112ms/step - loss: 1.2925 - val_loss: 0.5883\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "model architecture saved\n",
            "saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rotX_tNNSKra",
        "colab_type": "code",
        "outputId": "ad35afcc-1066-494e-c045-f63181f20b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "testInputs = [testUserReviews, testFoodReviews]\n",
        "# dat = pd.DataFrame(testInputs)\n",
        "# dat.to_csv(\"/content/gdrive/My Drive/DeepConn/Deep_Learning_Recommender_System//test_data.csv\")\n",
        "trueRating = np.array(list(test.loc[:, \"rating\"])).reshape((-1, 1))\n",
        "#predictions = deepconn.model.predict(testInputs)\n",
        "error = np.square(predictions - trueRating)\n",
        "print(\"MSE:\", np.average(error))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 1.0501385977129576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEA0LPy4j3Tg",
        "colab_type": "code",
        "outputId": "a78739c8-371b-4789-9e22-45a70e126e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "#the funtion is needed when loading the vectorizer\n",
        "def dummy_fun(doc):\n",
        "  return doc\n",
        "\n",
        "\n",
        "class HealthScoreCalculator():\n",
        "  def __init__(self):\n",
        "    self.weights = {\n",
        "\t'normal' : {'calories' : 1, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1}, \n",
        "\t'diabetes' : {'calories' : 1, 'protein' : 1, 'sugar' : 4.25, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 3, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1},\n",
        "\t'bp' : {'calories' : 1, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 9, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1},\n",
        "\t'obesity' : {'calories' : 7, 'protein' : 1, 'sugar' : 1.1, 'fat' : 1.1, 'sat_fat': 1.7, 'carbs' : 1, 'dietary_fiber' : 1.5, 'sodium' : 1, 'cholesterol' : 1.2, 'vitamin_a' : 1, 'vitamin_c' : 1, 'calcium' : 1, 'iron' : 1}\n",
        "\t}\n",
        "    self.predictedScores=None\n",
        "\n",
        "  def convToComStand(self,value):\n",
        "    if value.endswith('mg'):\n",
        "      value = value[:value.index('mg')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value) / 1000\n",
        "    elif value.endswith('g'):\n",
        "      value = value[:value.index('g')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value)\n",
        "    elif value.endswith('kcal'):\n",
        "      value = value[:value.index('kcal')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = float(value)\n",
        "\n",
        "    elif value.endswith('IU'):\n",
        "      value = value[:value.index('IU')]\n",
        "      value = value.replace(\",\", \"\")\n",
        "      value = value.replace(\" \", \"\")\n",
        "      value = (float(value) / 3.3) / 1000000\n",
        "    \n",
        "    return value\n",
        "\n",
        "  def elixir(self,allowed, weights, bmratio, type = 'normal'):\n",
        "    weights = weights[type]\n",
        "    database = json.load(open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/database.json\", 'rb'))\n",
        "    x = {}\n",
        "    for dish in database:\n",
        "      dishId = dish['dish_id']\n",
        "      nutrients = dish['nutrients']\n",
        "      if all(nutrients.values()):\n",
        "        for nutrient in nutrients:\n",
        "          value = nutrients[nutrient]\n",
        "          if value:\n",
        "            #converting to  common standard\n",
        "            value = self.convToComStand(value[0])\n",
        "            nutrients[nutrient] = value\n",
        "        #################################\n",
        "        recbn = ['protein', 'dietary_fiber']\n",
        "        recbase = 0\n",
        "        for i in recbn:\n",
        "          recbase += weights[i] * nutrients[i] / allowed[i]\n",
        "\n",
        "        part1 = 0\n",
        "        part2 = 0\n",
        "        if nutrients['carbs']:\n",
        "          part1 = weights['dietary_fiber'] * nutrients['dietary_fiber'] / nutrients['carbs']\n",
        "          part2 =  0.1 * (nutrients['carbs'] - nutrients['dietary_fiber'] - nutrients['sugar']) / nutrients['carbs']\n",
        "\n",
        "        recbase = recbase + part1 + part2\n",
        "        #################################\n",
        "        restbn = ['carbs', 'cholesterol', 'sodium', 'sat_fat', 'fat', 'sugar']\n",
        "        restbase = 0\n",
        "        for i in restbn:\n",
        "          restbase += weights[i] * nutrients[i] / allowed[i]\n",
        "\n",
        "        part1 = 0\n",
        "        part2 = 0\n",
        "        if nutrients['sugar'] and nutrients['carbs']:\n",
        "          part1 = weights['carbs'] * nutrients['sugar'] / nutrients['carbs']\n",
        "\n",
        "        if nutrients['sat_fat'] and nutrients['fat']:\n",
        "          part2 = weights['sat_fat'] * nutrients['sat_fat'] / nutrients['fat']\n",
        "        \n",
        "        restbase = part1 + part2\t\t\t\n",
        "        #################################\n",
        "        recan = ['vitamin_a', 'vitamin_c', 'calcium', 'iron']\n",
        "        recadd = 0\n",
        "        for i in recan:\n",
        "          recadd += weights[i] * nutrients[i] / allowed[i]\n",
        "        #################################\n",
        "\n",
        "        mult = bmratio\n",
        "        div = ((1 + mult) * restbase)\n",
        "        if div:\n",
        "          score = recbase + (mult * recadd) / div\n",
        "        else:\n",
        "          score = 0\n",
        "\n",
        "        x[dishId] = score\n",
        "    self.predictedScores=x\n",
        "    return x\n",
        "\n",
        "  def get_lat_long(self,ip_addr =\"me\"):\n",
        "    g = geocoder.ip(ip_addr)\n",
        "    return g.latlng\n",
        "\n",
        "  def get_temp(self,lat, lon):\n",
        "    owm = pyowm.OWM('9bb248641cc71b7ab1b7040317ec6ac9')\n",
        "    observation_list = owm.weather_around_coords(lat, lon)\n",
        "    tot_temp = 0\n",
        "    if observation_list != None:\n",
        "      for i in observation_list:\n",
        "        w = i.get_weather()\n",
        "        temp = w.get_temperature('fahrenheit')['temp']\n",
        "        tot_temp += temp\n",
        "\n",
        "      temp = tot_temp / len(observation_list)\n",
        "\n",
        "      return temp\n",
        "\n",
        "  def elevation(self,lat, lng):\n",
        "    loc = str(lat) + ',' + str(lng)\n",
        "    apikey = \"AIzaSyAd0cewCPnbRF_0082PULMybInWNhWgDjA\"\n",
        "    base_url = \"https://maps.googleapis.com/maps/api/elevation/json\"\n",
        "    params = dict()\n",
        "    params[\"locations\"] = str(loc)\n",
        "    params[\"key\"] = apikey\n",
        "    r = requests.get(base_url, params=params)\n",
        "    results = json.loads(r.text).get('results')\n",
        "    return 847\n",
        "    return results[0]['elevation']\n",
        "\n",
        "  def adaptive_daily_value(self,weight, height, gender, age, steps, height_travelled, bmratio):\n",
        "    latlong = self.get_lat_long()\n",
        "    temp = self.get_temp(*latlong)\n",
        "    altitude =self.elevation(*latlong)\n",
        "\n",
        "    allowed = {'calories' : 2079.35, 'protein' : 50, 'fat' : 70, 'sat_fat' : 24, 'carbs' : 310, 'sugar' : 30, 'dietary_fiber' : 30, 'sodium' : 2.3, 'cholesterol' : 300, 'vitamin_a' : 0.0008, 'vitamin_c' : 0.08, 'iron' : 0.0087, 'calcium' : 1}\n",
        "    \n",
        "    work = 9.8 * weight * height_travelled * 0.000239006 + weight * steps / 6000\n",
        "    \n",
        "    bmr = weight * 10 + 6.25 * height - 5 * age\n",
        "    if gender == 'm':\n",
        "      bmr += 5\n",
        "    else:\n",
        "      bmr -= 161\n",
        "\n",
        "    daily_cal = round(bmratio * bmr + work, 2)\n",
        "    if temp != None:\n",
        "      daily_cal = daily_cal * (1 + (85 - temp) / 800)\n",
        "\n",
        "      for i in allowed:\n",
        "        allowed[i] = allowed[i] * daily_cal / 2079.35\n",
        "\n",
        "    na_multi = 1 + 0.015 * (((temp - 32) * 0.56) - 23)\n",
        "    allowed['sodium'] = na_multi * allowed['sodium'] + (altitude / 1000) ** 2.5\n",
        "\n",
        "    return allowed\n",
        "  def calculateScore(self,height,weight,age,gender,condition,bmratio,steps, floors):\n",
        "    floors = floors * 10 * 3.28084\n",
        "    allowed = self.adaptive_daily_value(weight, height, gender, age, steps, floors, bmratio)\n",
        "    score = self.elixir(allowed, self.weights, bmratio, type = condition)\n",
        "    return score\n",
        "\n",
        "class RecommendDishes(HealthScoreCalculator):\n",
        "\n",
        "  def __init__(self,model,modelArch):\n",
        "    self.flavanoidDB=None\n",
        "    self.model=model\n",
        "    self.modelArch=modelArch\n",
        "    self.loadedTrainedModel=None\n",
        "    self.predictions=None\n",
        "    self.score=None\n",
        "    self.foodIdToNameMapping=None\n",
        "    self.loadIdMapping()\n",
        "    self.loadFlavanoidDB()\n",
        "    self.foodId=list(self.flavanoidDB.keys())\n",
        "    self.flavanoids=list(self.flavanoidDB.values())\n",
        "    self.loadModel(self.model,self.modelArch)\n",
        "    \n",
        "    print(\"......Loading Vectorizers......\\nUsing Tf-IDF Embedding \\n\")\n",
        "    self.userReviewVectorizer=pickle.load(open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/userReviewsTf-Idf.pickle\",\"rb\"))\n",
        "    self.flavanoidVectorizer=pickle.load(open(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/flavanoidsTf-Idf.pickle\",\"rb\"))\n",
        "    self.flavanoidsVector=self.flavanoidVectorizer.transform(self.flavanoids)\n",
        "    \n",
        "    HealthScoreCalculator.__init__(self)\n",
        "\n",
        "  def loadIdMapping(self):\n",
        "    self.foodIdToNameMapping=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/id_name_mapping.csv\",names=[\"id\",\"dish\"])\n",
        "\n",
        "  def loadFlavanoidDB(self):  \n",
        "    print(\"......Loading flavanoids data.......\")\n",
        "    rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "    self.flavanoidDB={}\n",
        "    for i in range(rawFlavanoids.shape[0]):\n",
        "      self.flavanoidDB[str(rawFlavanoids[\"id\"][i])]=rawFlavanoids[\"flavanoids\"][i].split(\"|\")\n",
        "    print(\"total flanavnoids={}\".format(len(self.flavanoidDB)))\n",
        "    \n",
        "  def loadModel(self,model,modelArch):\n",
        "    self.model=model\n",
        "    self.modelArch=modelArch\n",
        "    print(\".....Loading Trained Model.........\")\n",
        "    #rawData=pd.read_csv('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/unembedded_grouped_cleaned_data.csv')\n",
        "    #rawFlavanoids=pd.read_csv(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/newDatabase.csv\")\n",
        "    print(\".....Loading Architecture= {}\".format(modelArch))\n",
        "    jsonFile=open('/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/'+modelArch,'r')\n",
        "    loadedModelJson=jsonFile.read()\n",
        "    jsonFile.close()\n",
        "    self.loadedTrainedModel=model_from_json(loadedModelJson)\n",
        "    print(\"using {} model for recommendation\".format(model.split(\".h5\")[0]))\n",
        "    print(\".....Loading saved weights\")\n",
        "\n",
        "    self.loadedTrainedModel.load_weights(\"/content/gdrive/My Drive/Final Year Project/DeepConn/Deep_Learning_Recommender_System/\"+model)\n",
        "    \n",
        "    print(\"Trained model loaded successfully\")\n",
        "  \n",
        "  def cleanDoc(self,doc):#doc=list of string\n",
        "    print(\"Cleaning data\")\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in doc]\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tokens = [word for word in tokens if len(word) > 1]\n",
        "    print(\"Cleaned Input Data={}\".format(tokens))\n",
        "    return tokens\n",
        "\n",
        "  def prepareDataToPredict(self,userReview):#userReviews=string\n",
        "    print(\"Vectorizing data\")\n",
        "    userReview=self.cleanDoc(userReview.split(\" \"))    \n",
        "    #since rating has to be predicted for all the dishes\n",
        "    userReviewVector=self.userReviewVectorizer.transform([userReview]*len(self.flavanoids))\n",
        "    return self.foodId,[userReviewVector,self.flavanoidsVector]\n",
        "\n",
        "  def calculateRating(self,healthScores):\n",
        "    self.prediction=[]\n",
        "    for i in range(len(self.foodId)):\n",
        "      val=((self.predictions[i][0]/10)+healthScores[i]/10)*10\n",
        "      self.prediction.append(round(val if val<5 else get(48000,50000)/10000,4))\n",
        "    # self.prediction=np.clip(self.prediction,None,get(4800,5000)/1000)\n",
        "    \n",
        "  def recommend(self,userReview):\n",
        "    print(\".....Processing Input Data......\")\n",
        "    foodId,testInputs = self.prepareDataToPredict(userReview)  \n",
        "    self.predictions =self.loadedTrainedModel.predict(testInputs)\n",
        "    idToName=dict(zip(self.foodIdToNameMapping.id.tolist(),self.foodIdToNameMapping.dish.tolist()))\n",
        "    # for i in range(len(self.foodId)):\n",
        "    #   print(\"{}={}\".format(idToName[int(foodId[i])],self.predictions[i][0]))\n",
        "    return foodId,self.predictions\n",
        "  def displayTable(self,fieldNames,data):\n",
        "    table=PrettyTable()\n",
        "    table.field_names=fieldNames\n",
        "    for ele in data:\n",
        "      table.add_row(ele)\n",
        "    print(table)\n",
        "  def recommendDishWithHealthScore(self,userReview,height,weight,age,gender,condition,bmratio,steps,floors):\n",
        "    foodId,self.predictions=self.recommend(userReview)\n",
        "    self.scores=self.calculateScore(height,weight,age,gender,condition,bmratio,steps,floors)\n",
        "    healthScores=list(self.scores.values())\n",
        "    idToName=dict(zip(self.foodIdToNameMapping.id.tolist(),self.foodIdToNameMapping.dish.tolist()))\n",
        "    data=[]\n",
        "    self.calculateRating(healthScores)\n",
        "    for i in range(len(self.foodId)):\n",
        "      #data.append([idToName[int(foodId[i])],self.predictions[i][0],healthScores[i]])\n",
        "      data.append([idToName[int(foodId[i])],self.prediction[i],healthScores[i]])\n",
        "    data.sort(key=lambda x:x[1],reverse=True)\n",
        "    data=data[:5]\n",
        "    data.sort(key=lambda x:x[2],reverse=True)\n",
        "    self.displayTable([\"dish\",\"rating\",\"healthScore\"],data)\n",
        "    return foodId,self.predictions,self.score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x=RecommendDishes(\"SimpleRs.h5\",\"SimpleRsModelArchi.json\")\n",
        "y=x.recommendDishWithHealthScore(\"great food\",5.6,60,25,'m','normal',3000,10,22.1)\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "......Loading flavanoids data.......\n",
            "total flanavnoids=1380\n",
            ".....Loading Trained Model.........\n",
            ".....Loading Architecture= SimpleRsModelArchi.json\n",
            "using SimpleRs model for recommendation\n",
            ".....Loading saved weights\n",
            "Trained model loaded successfully\n",
            "......Loading Vectorizers......\n",
            "Using Tf-IDF Embedding \n",
            "\n",
            ".....Processing Input Data......\n",
            "Vectorizing data\n",
            "Cleaning data\n",
            "Cleaned Input Data=['great', 'food']\n",
            "+------------------------------------------------------------+--------+--------------------+\n",
            "|                            dish                            | rating |    healthScore     |\n",
            "+------------------------------------------------------------+--------+--------------------+\n",
            "|                         rava idli                          | 4.9998 | 0.7625991586705348 |\n",
            "|                       paneer bhurji                        | 4.9997 | 0.4396083154323811 |\n",
            "| chicken, potato, brie & thyme tart with caramelised onions | 4.9997 | 0.4196469788520587 |\n",
            "|                     hot garlic chutney                     | 4.9997 | 0.419640967941748  |\n",
            "|                        potato curry                        | 4.9994 | 0.4193627652475145 |\n",
            "+------------------------------------------------------------+--------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkONtPbaol_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}